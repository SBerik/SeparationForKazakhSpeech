xp_config:
  model_type: Separation
  model_name: &model_name PL_Dual_RNN_model
  dataset: ISSAI_KSC2
  speaker_num: &speaker_num 2
  
data:
  data_root: 'F:/ISSAI_KSC2_unpacked/DIHARD_DATA_INFO/CONCATED_DFS_train_crowdsourced_tvnews_tts=5000_k=2.csv'
  total_percent: 1.0
  train_percent: 0.8
  valid_percent: 0.1
  test_percent: 0.1
  shuffle: false
  num_workers: 0 
  batch_size: 1
  pin_memory: true
  sample_rate: 16000
  chunk_size: 32000
  least_size: 16000
  seed: 42

optim: &optim
  type: Adam  # default 
  Adam: 
    lr: !!float 0.0005
    weight_decay: 1.0e-05  
  SGD:
    lr: 0.0005  
    momentum: 0.9

scheduler: &scheduler
  min_lr: !!float 1.0e-8
  patience: 2
  factor: 0.5

clip_norm: &clip_norm
  max_norm: 5

training: &training
  alpha: 0.55
  beta: 0.45

model:
  in_channels: 256
  out_channels: 64 
  hidden_channels: 128
  kernel_size: 2
  rnn_type: LSTM
  norm: ln
  dropout: 0
  bidirectional: true
  num_layers: 6
  K: 250
  speaker_num: *speaker_num
  training: *training
  optim_params: *optim
  scheduler: *scheduler
  clip_norm: *clip_norm  

trainer:
  accelerator: gpu
  devices: 1
  num_nodes: 1 
  fast_dev_run: false 
  precision: 32
  accumulate_grad_batches: 1
  profiler: simple
  val_check_interval: 1.0
  check_val_every_n_epoch: 1
  max_epochs: -1
  gradient_clip_val: 5
  detect_anomaly: false
  enable_model_summary: true # nn info
  deterministic: false
  benchmark: true

model_ckpt:
  monitor: val_loss
  filename: '{epoch:02d}'
  save_last: true

tb_logger:
  name: *model_name

early_stop:
  mode: min 
  patience: 8

# inferece
# barebones: true # enable all features that may impact raw speed are disabled 
# inferece_mode: true # inference mode

#test model
# fast_dev_run: false
# overfit_batches: 100 or 100.0 (batches num and %) of dataset:


