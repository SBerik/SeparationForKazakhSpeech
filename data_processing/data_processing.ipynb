{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb38771-56e7-450c-a733-03c226d694cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import re \n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e7b9dc-1619-419c-aa1d-ea8213ec82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\"sample1\": \"C:/Users/b.smadiarov/Diploma/DualPathRNN/data/samples/5ed8a1c0f3ea2.flac\",\n",
    "         \"sample2\": \"C:/Users/b.smadiarov/Diploma/DualPathRNN/data/samples/5f2b0a06ceb18.flac\",\n",
    "         \"mixed\": \"/home/berik/workspace/Diploma/DualPathRNN/data/mixed\"\n",
    "        }\n",
    "\n",
    "glob_paths = {'KS2_raw': 'F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/**/**/*.flac'} \n",
    "\n",
    "seed = 42\n",
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebfd26e-e4ac-4f3a-8ce6-12754e91ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd2aaf-2116-4054-88f9-b56ad3e71266",
   "metadata": {},
   "source": [
    "#### Generate samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cac6ac8-5215-4e77-bb68-0eba02d90ace",
   "metadata": {},
   "source": [
    "Prepare sourced folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca1322b-268f-4ec4-9d22-4ad0fff22d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_folders = set(['crowdsourced', 'tv_show', 'poition']) \n",
    "\n",
    "# Критерий: нету посторонних звуков \n",
    "# Выбери какие тебе подойдут для лейблов. Но если не подойдет то можно читать датафрейм и искать все такие видео которые имеют \n",
    "#три интервала - \"не говорит, говорит, не говорит\" - поэтому ты и выбрал crowdsourced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd8af5d-7bbc-4819-bfdc-ae41c59a89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если не жалко памяти.\n",
    "destination_base = 'F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/Targets/' # так как destination base может поменяться.\n",
    "\n",
    "# По хорошему лучше их объединить в одну папку - просто дав им разные имена\n",
    "for t in glob(glob_paths['KS2_raw']):\n",
    "    t = t.replace('\\\\', '/') # 'F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/Train/crowdsourced/475mnd37hvnf3t94.flac'\n",
    "    splited_t = set(t.split('/'))\n",
    "    if splited_t.intersection(list_folders):\n",
    "        # shutil.move(t, destination_base + re.sub(r'.*ISSAI_KSC2/', '', t).replace('/', '-'))\n",
    "        print(\"Файл успешно перемещен!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de65ae-1368-4b57-9436-f2464bede438",
   "metadata": {},
   "source": [
    "**Generate samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a0c8510-7648-4229-855f-1d272ff0fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(file_path: str):\n",
    "    return os.path.splitext(os.path.basename(file_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9358921-e3c8-4abc-bebe-56beadb2afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(audio_1: str, audio_2: str, sr=16000):\n",
    "    y1, sr1 = librosa.load(audio_1, sr=sr)\n",
    "    y2, sr2 = librosa.load(audio_2, sr=sr)\n",
    "    assert sr1 == sr2, \"Different sample rates!\"\n",
    "\n",
    "    # Idea 1.\n",
    "    # min_length = min(len(y1), len(y2))\n",
    "    # y1 = y1[:min_length]\n",
    "    # y2 = y2[:min_length]\n",
    "    # # Idea 2.\n",
    "    # silence_threshold = 1e-5  \n",
    "    # is_silent_1 = np.all(np.abs(y1[-int(sr*0.1):]) < silence_threshold)\n",
    "    # is_silent_2 = np.all(np.abs(y2[-int(sr*0.1):]) < silence_threshold)\n",
    "    # if len(y1) < len(y2):\n",
    "    #     y1 = np.pad(y1, (0, len(y2) - len(y1))) if is_silent_1 else y1\n",
    "    # else:\n",
    "    #     y2 = np.pad(y2, (0, len(y1) - len(y2))) if is_silent_2 else y2\n",
    "\n",
    "    # Idea 3.\n",
    "    if len(y1) < len(y2):\n",
    "        y1 = np.pad(y1, (0, len(y2) - len(y1)))\n",
    "    else:\n",
    "        y2 = np.pad(y2, (0, len(y1) - len(y2)))\n",
    "\n",
    "    overlay = y1 + y2\n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd473e47-93ea-40bf-a846-bb9571c4876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скорее всего его нужно будет перемешать - так как говорящие идут одним за одним.\n",
    "tracklist = glob('F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/Targets/*.flac')\n",
    "random.shuffle(tracklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afd3e1-9b93-425d-ab05-33fb7d757aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Короткие записи сливались с короткими записями. \n",
    "# Есть ли разница в том что в начале двух аудио тишина например. Возможно стоит обрезать концы и начало аудио. \n",
    "# Нужно ли что вообще участков где бы человек говорил - или только speech учатски сигнала были. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ce7520-e968-465e-9a46-55b81b879d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАМЕЧАНИЕ: ПОРАЖДАЮ Я ИЗ ПАПКИ TARGETS! - ПОЭТОМУ ПУТИ МЕНЯ НЕ НУЖНО. \n",
    "# Не забудь добавить tqdm.\n",
    "# Берем парами \n",
    "\n",
    "tracklist = ['/home/berik/workspace/Diploma/DualPathRNN/data/samples/5ed8a1c0f3ea2.flac', \n",
    "            '/home/berik/workspace/Diploma/DualPathRNN/data/samples/5f2b0a06ceb18.flac']\n",
    "\n",
    "# for t in tqdm(tracklist):\n",
    "for i in range(0, len(tracklist)-1, 2):\n",
    "    t1, t2 = tracklist[i], tracklist[i+1]\n",
    "    overlay = overlap(t1, t2)\n",
    "    audio_name = f\"{paths['mixed']}/{get_file_name(t1)}_{get_file_name(t2)}.flac\"\n",
    "    sf.write(f\"{audio_name}\", overlay, samplerate=16000)\n",
    "    df = pd.DataFrame({'mixed_audio': [audio_name], 'audio_1': [t1], 'audio_2': [t2]})\n",
    "    df.to_csv(f\"{audio_name.replace('.flac', '.csv')}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f87a3-c45d-438c-b73f-a03c4b0aebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full dataset DF\n",
    "annotations = glob('/home/berik/workspace/Diploma/DualPathRNN/data/mixed/*.csv')\n",
    "all_dfs = []\n",
    "for csv in tqdm(annotations):\n",
    "    df = pd.read_csv(csv)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "concated_df = pd.concat(all_dfs).reset_index(drop=True)\n",
    "concated_df.to_csv('/home/berik/workspace/Diploma/DualPathRNN/data/DATA_INFO/CONCATED_DFS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32b1e6-b841-492e-9ed3-d09d614538f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить аудио\n",
    "# Загрузить его аннотацию\n",
    "# Получить аннотационные интервалы\n",
    "# Найти время участок где человек не говорит в начала/конце\n",
    "# Записать это аудио. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7198925-d109-4a4c-b8f5-ce20eac86907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1.7 27200.0\n",
      "end 9.25 148000.0\n",
      "162480.0 162474\n"
     ]
    }
   ],
   "source": [
    "# Добавить этот код в функцию overlap. \n",
    "\n",
    "audio_name = '/home/berik/workspace/Diploma/DualPathRNN/data/samples/5ed8a1c0f3ea2.flac'\n",
    "audio, sr = librosa.load(audio_name, sr=16000) \n",
    "annotation_csv = audio_name.replace('.flac', '.csv') \n",
    "df = pd.read_csv(annotation_csv)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# DataFrame имеет следующую структуру: speech | start_time | end_time | utt_time | audio_id\n",
    "# нужно взять первый speech == '1' и у него \"start\". Затем нужно взять последний speech == '1' и взять у него \"end\".\n",
    "# Делаем именно таким образом - т.к. участок где человек не говорит может не быть, тогда начало и конец должны совпадать.\n",
    "\n",
    "start = df[df['speech'] == 1].iloc[0]['start_time']\n",
    "end = df[df['speech'] == 1].iloc[-1]['end_time']\n",
    "\n",
    "print('start', start, start * sr)\n",
    "print('end', end, end * sr)\n",
    "print(10.155 * sr, len(audio)-1)\n",
    "    \n",
    "# После этого мы знаем start, end - это временные точки. Теперь нужно обрезать исходное аудио в отрезке [start, end]\n",
    "trimmed_audio = audio[int(start * sr):int(end * sr)]\n",
    "\n",
    "new_audio_name = audio_name.replace(f\"{get_file_name (audio_name)}\", f\"trimmed_{get_file_name (audio_name)}\") \n",
    "# Если нужно сохранить обрезанное аудио, используем следующий код\n",
    "sf.write(new_audio_name, trimmed_audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2245676-c761-478f-a77d-c9a8514b49a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>utt_time</th>\n",
       "      <th>audio_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.700</td>\n",
       "      <td>1.700</td>\n",
       "      <td>F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/Train/crowds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>9.250</td>\n",
       "      <td>7.550</td>\n",
       "      <td>F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/Train/crowds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9.25</td>\n",
       "      <td>10.155</td>\n",
       "      <td>0.905</td>\n",
       "      <td>F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/Train/crowds...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speech  start_time  end_time  utt_time  \\\n",
       "0       0        0.00     1.700     1.700   \n",
       "1       1        1.70     9.250     7.550   \n",
       "2       0        9.25    10.155     0.905   \n",
       "\n",
       "                                            audio_id  \n",
       "0  F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/Train/crowds...  \n",
       "1  F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/Train/crowds...  \n",
       "2  F:/ISSAI_KSC2_unpacked/ISSAI_KSC2/Train/crowds...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f019a-c239-43dc-a0bc-56a2dcbcd6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
