{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14234ca6-8b70-4324-9b78-5081273407d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc69ca4-37f6-4aa3-be38-7222b2822758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from glob import glob\n",
    "import torch as th\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "from typing import Optional, List\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd \n",
    "from tqdm.notebook import tqdm \n",
    "import numpy as np\n",
    "\n",
    "from utils.measure_time import measure_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fd87ed-9d94-4344-bac5-49e2010bba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from utils.load_config import load_config  \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-p\", \"--hparams\", type=str, default=\"./configs/train_rnn.yml\", help=\"hparams config file\")\n",
    "args, unknown = parser.parse_known_args()  # Игнорирует нераспознанные аргументы\n",
    "cfg = load_config(args.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b9e804-b59b-414d-87d7-7821d1df20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 420\n",
      "Size of validation set: 63\n",
      "Elapsed time 'setup': 00:00:02.20\n"
     ]
    }
   ],
   "source": [
    "datamodule = AudioDataModule(**cfg['data']).setup(stage = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8888a7-e1c6-4545-8b6c-a0a6de82e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554598ec-535b-4159-baa4-128aac54fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение первого батча данных из DataLoader\n",
    "dataloader = dataloaders['train'] \n",
    "sample_mix, sample_refs = next(iter(dataloader))  # Используем iter и next для доступа к данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843cfc43-6534-4cf7-bc21-9431d9410bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.0016, 0.0045, 0.0016,  ..., 0.0505, 0.1465, 0.1519]])] \n",
      "\n",
      "chunks_num 1 \n",
      "\n",
      "tensor([[0.0016, 0.0045, 0.0016,  ..., 0.0505, 0.1465, 0.1519]]) \n",
      "\n",
      "torch.Size([1, 32000]) \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "spekears num 2 \n",
      "\n",
      "firs_speaker list: [tensor([[-0.0042, -0.0083, -0.0139,  ..., -0.0009, -0.0040, -0.0038]])] \n",
      "\n",
      "chunks_nums 1 \n",
      "\n",
      "torch.Size([1, 32000]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample_mix, '\\n')\n",
    "print('chunks_num', len(sample_mix), '\\n')\n",
    "print(sample_mix[0], '\\n')\n",
    "print(sample_mix[0].shape, '\\n')\n",
    "print('----------------------------------------------', '\\n')\n",
    "print('spekears num', len(sample_refs), '\\n')\n",
    "print('firs_speaker list:', sample_refs[0], '\\n')\n",
    "print('chunks_nums', len(sample_refs[0]), '\\n')\n",
    "print(sample_refs[0][0].shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e982a81-f8d1-4973-9b23-7b39b24e757c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Testing dataloaders LAST UPDATE. 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f08438-1181-491b-bd12-577d472318b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from utils.load_config import load_config  \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-p\", \"--hparams\", type=str, default=\"./configs/train_rnn.yml\", help=\"hparams config file\")\n",
    "args, unknown = parser.parse_known_args()  # Игнорирует нераспознанные аргументы\n",
    "cfg = load_config(args.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68d6cd7-d5a3-4ecb-8606-a9cc3746c472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 3140\n",
      "Size of validation set: 641\n",
      "Elapsed time 'setup': 00:00:02.50\n"
     ]
    }
   ],
   "source": [
    "from data.DiarizationDataset import DiarizationDataset\n",
    "\n",
    "datamodule = DiarizationDataset(**cfg['data']).setup(stage = 'train')\n",
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbfd334-a39e-476d-b91a-421e81787a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from typing import List, Tuple\n",
    "import os.path as ospth\n",
    "\n",
    "def get_file_name(file_path: str):\n",
    "    return ospth.splitext(ospth.basename(file_path))[0]\n",
    "\n",
    "def handle_df(audios: List[Tuple[int, str]]) -> dict:\n",
    "    scp_dict = dict()\n",
    "    for audio in audios:\n",
    "        common_len, l = audio\n",
    "        if len(audio) != 2:\n",
    "            raise RuntimeError(\"Format error in\")\n",
    "        if len(audio) == 2:\n",
    "            key, value = f\"{get_file_name (l)}.flac\", l\n",
    "        if key in scp_dict:\n",
    "            raise ValueError(\"Duplicated key \\'{0}\\' exists in {1}\".format(\n",
    "                l, l))\n",
    "        scp_dict[key] = {'common_len': common_len, 'name': value}\n",
    "    return scp_dict\n",
    "        \n",
    "    \n",
    "def read_wav(fname, return_rate=False):\n",
    "    '''\n",
    "         Read wavfile using Pytorch audio\n",
    "         input:\n",
    "               fname: wav file path\n",
    "               return_rate: Whether to return the sampling rate\n",
    "         output:\n",
    "                src: output tensor of size C x L \n",
    "                     L is the number of audio frames \n",
    "                     C is the number of channels. \n",
    "                sr: sample rate\n",
    "    '''\n",
    "    src, sr = torchaudio.load(fname, channels_first=True)\n",
    "    if return_rate:\n",
    "        return src.squeeze(), sr\n",
    "    else:\n",
    "        return src.squeeze()\n",
    "\n",
    "\n",
    "def write_wav(fname, src, sample_rate):\n",
    "    '''\n",
    "         Write wav file\n",
    "         input:\n",
    "               fname: wav file path\n",
    "               src: frames of audio\n",
    "               sample_rate: An integer which is the sample rate of the audio\n",
    "         output:\n",
    "               None\n",
    "    '''\n",
    "    torchaudio.save(fname, src, sample_rate)\n",
    "\n",
    "\n",
    "class CustomAudioReader(object):\n",
    "    '''\n",
    "        Class that reads Wav format files\n",
    "        Input:\n",
    "            scp_path (str): a different scp file address\n",
    "            sample_rate (int, optional): sample rate (default: 8000)\n",
    "            chunk_size (int, optional): split audio size (default: 32000(4 s))\n",
    "            least_size (int, optional): Minimum split size (default: 16000(2 s))\n",
    "        Output:\n",
    "            split audio (list)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, scp_path, sample_rate=8000, chunk_size=32000, least_size=16000):\n",
    "        super(CustomAudioReader, self).__init__()\n",
    "        self.sample_rate = sample_rate\n",
    "        self.index_dict = handle_df(scp_path)\n",
    "        self.keys = list(self.index_dict.keys())\n",
    "        # print(self.keys[0])\n",
    "        self.audio = []\n",
    "        self.chunk_size = chunk_size\n",
    "        self.least_size = least_size\n",
    "        self.split()\n",
    "\n",
    "    def split(self):\n",
    "        '''\n",
    "            split audio with chunk_size and least_size\n",
    "        '''\n",
    "        for key in self.keys:\n",
    "            common_len, name = self.index_dict[key]['common_len'], self.index_dict[key]['name']\n",
    "            utt = read_wav(name)\n",
    "            utt = utt[:common_len]\n",
    "            if utt.shape[0] < self.least_size:\n",
    "                continue\n",
    "            if utt.shape[0] > self.least_size and utt.shape[0] < self.chunk_size:\n",
    "                gap = self.chunk_size-utt.shape[0]\n",
    "                self.audio.append(F.pad(utt, (0, gap), mode='constant'))\n",
    "            if utt.shape[0] >= self.chunk_size:\n",
    "                start = 0\n",
    "                while True:\n",
    "                    if start + self.chunk_size > utt.shape[0]:\n",
    "                        break\n",
    "                    self.audio.append(utt[start:start+self.chunk_size])\n",
    "                    start += self.least_size\n",
    "\n",
    "    def get_num_after_splitting(self):\n",
    "        print(len(self.audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1eee3f8-0ee1-48eb-a9d9-de6f33e56535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class CustomDatasets(torch.utils.data.Dataset):\n",
    "    '''\n",
    "       Load audio data\n",
    "       mix_scp: file path of mix audio (type: str)\n",
    "       ref_scp: file path of ground truth audio (type: list[spk1,spk2])\n",
    "       chunk_size (int, optional): split audio size (default: 32000(4 s))\n",
    "       least_size (int, optional): Minimum split size (default: 16000(2 s))\n",
    "    '''\n",
    "\n",
    "    def __init__(self, df=None, sample_rate=16000, chunk_size=32000, least_size=16000):\n",
    "        super(torch.utils.data.Dataset, self).__init__()\n",
    "        k = len(df.iloc[0]) - 2\n",
    "        mix_scp = []\n",
    "        ref_scp = [[] for _ in range (k)]\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            common_len_idx = row['common_len_idx']\n",
    "            mix_scp.append([common_len_idx, row['mixed_audio']])\n",
    "            i = 0\n",
    "            for col in df.columns[2:]:\n",
    "                audio_value = row[col]\n",
    "                ref_scp[i].append([common_len_idx, audio_value])\n",
    "                i += 1 \n",
    "    \n",
    "        self.mix_audio = CustomAudioReader(mix_scp, sample_rate=sample_rate, chunk_size=chunk_size, least_size=least_size).audio\n",
    "        self.ref_audio = [CustomAudioReader(r, sample_rate=sample_rate, chunk_size=chunk_size, least_size=least_size).audio for r in ref_scp]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mix_audio)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.mix_audio[index], [ref[index] for ref in self.ref_audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "717663dd-4e43-4806-93fa-a7c294bd36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.measure_time import measure_time \n",
    "import torch as th\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "class TestingDiarizationDataset:\n",
    "    def __init__(self, data_root = './', train_percent = 0.75, valid_percent = 0.15, test_percent = 0.0, shuffle=False, \n",
    "                 num_workers=0, batch_size=1, pin_memory = False, sample_rate=8000, chunk_size=32000, least_size=16000, seed = 42):\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.pin_memory = pin_memory\n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self.least_size = least_size\n",
    "        self.seed = seed\n",
    "        self._set_seed(seed)\n",
    "        self.g = th.Generator()\n",
    "        self.g.manual_seed(seed)\n",
    "        full_data_df = pd.read_csv(data_root) \n",
    "        assert math.isclose(train_percent + valid_percent + test_percent, 1.0, rel_tol=1e-9), \"Sum doesnt equal to 1\" \n",
    "        train_size = int(train_percent * len(full_data_df)) \n",
    "        val_size = int(valid_percent * len(full_data_df)) \n",
    "        test_size = len(full_data_df) - train_size - val_size\n",
    "        self.train_df = full_data_df.iloc[:train_size] \n",
    "        self.val_df = full_data_df.iloc[train_size:train_size + val_size] \n",
    "        self.test_df = full_data_df.iloc[train_size + val_size:]\n",
    "         \n",
    "    @measure_time\n",
    "    def setup(self, stage = 'train'):\n",
    "        assert stage in ['train', 'eval'], \"Invalid stage\" \n",
    "        if stage == 'train': \n",
    "            self.train_dataset = CustomDatasets(self.train_df, \n",
    "                                            sample_rate = self.sample_rate,\n",
    "                                            chunk_size = self.chunk_size,\n",
    "                                            least_size = self.least_size)\n",
    "            print(f\"Size of training set: {len(self.train_dataset)}\")\n",
    "            self.val_dataset = CustomDatasets(self.val_df, \n",
    "                                        sample_rate = self.sample_rate,\n",
    "                                        chunk_size = self.chunk_size,\n",
    "                                        least_size = self.least_size)\n",
    "            print(f\"Size of validation set: {len(self.val_dataset)}\")\n",
    "        # To Do \n",
    "        # self.test_dataset\n",
    "        \n",
    "        return self # warning! \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.train_dataset,\n",
    "                                    batch_size = self.batch_size,\n",
    "                                    pin_memory = self.pin_memory,\n",
    "                                    shuffle = self.shuffle,\n",
    "                                    num_workers = self.num_workers,\n",
    "                                    worker_init_fn=self.seed_worker,\n",
    "                                    generator=self.g)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.train_dataset,\n",
    "                                    batch_size = self.batch_size,\n",
    "                                    pin_memory = self.pin_memory,\n",
    "                                    shuffle = False,\n",
    "                                    num_workers = self.num_workers,\n",
    "                                    worker_init_fn=self.seed_worker,\n",
    "                                    generator=self.g)\n",
    "\n",
    "    def _set_seed(self, seed: int):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        th.manual_seed(seed)\n",
    "        th.cuda.manual_seed_all(seed)\n",
    "\n",
    "    def seed_worker(self, worker_id):\n",
    "        worker_seed = th.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "        \n",
    "    # ToDo\n",
    "    # def test_dataloader(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b33ec27-5bc7-441f-987d-6dcf7680e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 3140\n",
      "Size of validation set: 641\n",
      "Elapsed time 'setup': 00:00:02.54\n"
     ]
    }
   ],
   "source": [
    "datamodule = TestingDiarizationDataset(**cfg['data']).setup(stage = 'train')\n",
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86eab67a-d15b-410f-8119-737850f6ce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182]])\n",
      "chunks_num 1\n",
      "tensor([0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182])\n",
      "torch.Size([32000])\n",
      "----------------------------------------------\n",
      "spekears num 2\n",
      "firs_speaker list: tensor([[ 0.0179,  0.0152,  0.0104,  ...,  0.0005, -0.0008, -0.0029]])\n",
      "chunks_nums 1\n",
      "torch.Size([32000])\n"
     ]
    }
   ],
   "source": [
    "# Получение первого батча данных из DataLoader\n",
    "dataloader = dataloaders['train'] \n",
    "sample_mix, sample_refs = next(iter(dataloader))  \n",
    "print(sample_mix)\n",
    "print('chunks_num', len(sample_mix))\n",
    "print(sample_mix[0])\n",
    "print(sample_mix[0].shape)\n",
    "print('----------------------------------------------')\n",
    "print('spekears num', len(sample_refs))\n",
    "print('firs_speaker list:', sample_refs[0])\n",
    "print('chunks_nums', len(sample_refs[0]))\n",
    "print(sample_refs[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd2cea-0cee-4641-a922-94bd4a456d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182]])\n",
    "chunks_num 1\n",
    "tensor([0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182])\n",
    "torch.Size([32000])\n",
    "----------------------------------------------\n",
    "spekears num 2\n",
    "firs_speaker list: tensor([[ 0.0179,  0.0152,  0.0104,  ...,  0.0005, -0.0008, -0.0029]])\n",
    "chunks_nums 1\n",
    "torch.Size([32000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2e86d-74b8-47d6-8a43-7020ac31c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of training set: 3140\n",
    "# Size of validation set: 641\n",
    "# Elapsed time 'setup': 00:00:03.57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0c6d97-73b1-415b-acdf-c64c20b4eeab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Developed | Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193324bc-b9dc-4e79-906a-79f677b42d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taudio: tensor(17.5640, device='cuda:0')\n",
      "another taudio: tensor(18.1067)\n",
      "my sdr: tensor(3.0031) \n",
      "\n",
      "my sisnr: 47.03880310058594\n",
      "reversed: 47.03880310058594\n",
      "sisnr taudio: 51.2036018371582\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from losses import sdr_loss\n",
    "from torchmetrics.audio import PermutationInvariantTraining\n",
    "from torchmetrics.functional.audio import signal_distortion_ratio\n",
    "from torchmetrics.audio import SignalDistortionRatio\n",
    "from torchmetrics.functional.audio import permutation_invariant_training\n",
    "\n",
    "from losses import sisnr_pit\n",
    "from torchmetrics.audio import ScaleInvariantSignalNoiseRatio\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "batch = 1\n",
    "spk = 2\n",
    "time = 32000\n",
    "sample_mix = [torch.randn(batch, time) for _ in range(spk)]\n",
    "sample_refs = [torch.randn(batch, time) for _ in range(spk)]\n",
    "\n",
    "# print(sample_mix[0].shape)\n",
    "\n",
    "# Функция для смешивания тензоров с заданной схожестью\n",
    "def mix_tensors_with_similarity(tensor1, tensor2, unsimilarity=0.05):\n",
    "    # Векторная интерполяция между tensor1 и tensor2\n",
    "    return unsimilarity * tensor1 + (1 - unsimilarity) * tensor2\n",
    "\n",
    "# Применяем смешивание для всех спикеров\n",
    "sample_mix_similar = [\n",
    "    mix_tensors_with_similarity(m, r, unsimilarity=0.999999999999999999999999)\n",
    "    for m, r in zip(sample_mix, sample_refs)\n",
    "]\n",
    "\n",
    "sample_mix = sample_mix_similar\n",
    "r_sample_mix = sample_mix[::-1]\n",
    "\n",
    "sample_mix_tensor = torch.stack(sample_mix, dim=1)  # по оси 1 (spk) ожидаемый вывод: torch.Size([1, 2, 3200])\n",
    "sample_refs_tensor = torch.stack(sample_refs, dim=1)  # по оси 1 (spk)  # ожидаемый вывод: torch.Size([1, 2, 3200])\n",
    "r_sample_mix_tensor = torch.stack(r_sample_mix, dim=1)  # по оси 1 (spk) ожидаемый вывод: torch.Size([1, 2, 3200])\n",
    "\n",
    "# print(sample_mix_tensor.shape)\n",
    "# print(sample_refs_tensor.shape)\n",
    "\n",
    "pit = PermutationInvariantTraining(signal_distortion_ratio, mode=\"speaker-wise\", eval_func=\"max\").to('cuda')\n",
    "print('taudio:', - pit(r_sample_mix_tensor, sample_refs_tensor)) # Warining \"-\" minus before\n",
    "sdr = SignalDistortionRatio()\n",
    "print('another taudio:', - sdr(sample_mix_tensor, sample_refs_tensor)) # Warining \"-\" minus before\n",
    "print('my sdr:', sdr_loss(sample_mix, sample_refs), '\\n')\n",
    "# print('')\n",
    "\n",
    "print('my sisnr:', sisnr_pit(sample_mix, sample_refs).item())\n",
    "print('reversed:', sisnr_pit(r_sample_mix, sample_refs).item())\n",
    "sisnr = ScaleInvariantSignalNoiseRatio().to('cuda')\n",
    "sample_mix_tensor = sample_mix_tensor.to('cuda')\n",
    "sample_refs_tensor = sample_refs_tensor.to('cuda')\n",
    "sisnr.update(sample_mix_tensor, sample_refs_tensor)\n",
    "TEMP = sisnr.compute()\n",
    "print('sisnr taudio:', - TEMP.item()) # Warining \"-\" minus before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9858b80-a4ae-49eb-ae8f-63b5b9e028d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taudio: tensor(-138.7370)\n"
     ]
    }
   ],
   "source": [
    "seed = 44\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "batch = 1\n",
    "spk = 2\n",
    "time = 32000\n",
    "sample_mix = [torch.randn(batch, time) for _ in range(spk)]\n",
    "sample_refs = [torch.randn(batch, time) for _ in range(spk)]\n",
    "\n",
    "# print(sample_mix[0].shape)\n",
    "\n",
    "# Функция для смешивания тензоров с заданной схожестью\n",
    "def mix_tensors_with_similarity(tensor1, tensor2, unsimilarity=0.05):\n",
    "    # Векторная интерполяция между tensor1 и tensor2\n",
    "    return unsimilarity * tensor1 + (1 - unsimilarity) * tensor2\n",
    "\n",
    "# Применяем смешивание для всех спикеров\n",
    "sample_mix_similar = [\n",
    "    mix_tensors_with_similarity(m, r, unsimilarity=0.000000000000000000000000000000001)\n",
    "    for m, r in zip(sample_mix, sample_refs)\n",
    "]\n",
    "\n",
    "sample_mix = sample_mix_similar\n",
    "r_sample_mix = sample_mix[::-1]\n",
    "\n",
    "sample_mix_tensor = torch.stack(sample_mix, dim=1)  # по оси 1 (spk) ожидаемый вывод: torch.Size([1, 2, 3200])\n",
    "sample_refs_tensor = torch.stack(sample_refs, dim=1)  # по оси 1 (spk)  # ожидаемый вывод: torch.Size([1, 2, 3200])\n",
    "r_sample_mix_tensor = torch.stack(r_sample_mix, dim=1)  # по оси 1 (spk) ожидаемый вывод: torch.Size([1, 2, 3200])\n",
    "\n",
    "pit2 = PermutationInvariantTraining(signal_distortion_ratio, mode=\"speaker-wise\", eval_func=\"max\")\n",
    "print('taudio:', - pit2(r_sample_mix_tensor, sample_refs_tensor)) # Warining \"-\" minus before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964ef24-8aca-4b84-963d-33e355df23d0",
   "metadata": {},
   "source": [
    "Вердикт - использовать мою функцию в качестве sisnr и использовать torchaudio для sdr. \n",
    "\n",
    "Интересный факт - функция sdr ведет себя sdr(x) -> min как sisnr (x) -> min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f06659-4580-461f-8ae9-da5af422d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torchmetrics.audio import PermutationInvariantTraining as PIT\n",
    "from torchmetrics.functional.audio import signal_distortion_ratio as sdr\n",
    "from torchmetrics.functional.audio import scale_invariant_signal_noise_ratio as sisnr\n",
    "# from torchmetrics.audio import ScaleInvariantSignalNoiseRatio as sisnr\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from losses import sisnr_pit\n",
    "from utils.load_config import load_config  \n",
    "from models import MODELS\n",
    "from data.DiarizationDataset import DiarizationDataset\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-p\", \"--hparams\", type=str, default=\"./configs/dev_dualpathrnn.yml\", help=\"hparams config file\")\n",
    "args, unknown = parser.parse_known_args()  \n",
    "cfg = load_config(args.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a308b779-18c9-4835-a776-3077a6147d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set: 848\n",
      "Elapsed time 'setup': 00:00:00.72\n"
     ]
    }
   ],
   "source": [
    "model_class = MODELS[cfg['xp_config']['model_type']]\n",
    "model = model_class(**cfg['model'])\n",
    "device = cfg['trainer']['device']\n",
    "model.to(device)\n",
    "datamodule = DiarizationDataset(**cfg['data']).setup(stage = 'eval')\n",
    "test_dataloader = datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e2f5ad-b97b-4454-bdcf-928cbe62156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = './weights/__DualPath_RNN_179_-3.1895.pt'\n",
    "dicts = torch.load(weight, map_location=device, weights_only=False)\n",
    "model.load_state_dict(dicts['model_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "pit_sdr = PIT(sdr).to(device)\n",
    "pit_sisnr = PIT(sisnr).to(device)\n",
    "\n",
    "loss_funcs = {name: PIT(func).to(cfg['trainer']['device']) for name, func in {\"sisnr\": sisnr, \"sdr\": sdr}.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efd832d-78dd-48be-b29d-bce3e8d0f156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cb24bbbf534819a8c32b3f92fd451e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/848 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdr -5.2180030130174995\n",
      "sisnr -4.563263170192686\n"
     ]
    }
   ],
   "source": [
    "from utils.training import * \n",
    "\n",
    "running_sdr = 0.0\n",
    "running_sisnr = 0.0\n",
    "for inputs, labels in tqdm(test_dataloader):\n",
    "    inputs, labels = inputs.to(device), [l.to(device) for l in labels]\n",
    "    with torch.no_grad():\n",
    "        outputs = [s.detach() for s in model(inputs)]\n",
    "        outputs, labels = tensify(outputs).to(device), tensify(labels).to(device) \n",
    "        losses = {'sisnr': - loss_funcs['sisnr'](outputs, labels),\n",
    "                  'sdr': - loss_funcs['sdr'](outputs, labels)} \n",
    "        running_sisnr += losses['sisnr'].item()\n",
    "        running_sdr += losses['sdr'].item()\n",
    "        pit_sdr.update(outputs, labels)\n",
    "        pit_sisnr.update(outputs, labels)\n",
    "\n",
    "print('sdr', running_sdr / len(test_dataloader))\n",
    "print('sisnr', running_sisnr / len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471f3b6-170b-4181-816c-83b7908e2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd01ae-9b8b-45f8-8c82-faf719452de2",
   "metadata": {},
   "source": [
    "#### Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614e4453-a2d5-482c-ba2b-4313e26446e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 135\n",
      "Size of validation set: 15\n",
      "Elapsed time 'setup': 00:00:00.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\b.smadiarov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parametrs: 68353025\n",
      "Size of model: 260.75 MB, in float32\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter as TensorBoard\n",
    "from torchmetrics.audio import PermutationInvariantTraining as PIT\n",
    "from torchmetrics.functional.audio import signal_distortion_ratio as sdr\n",
    "from torchmetrics.functional.audio import scale_invariant_signal_noise_ratio as sisnr\n",
    "\n",
    "from utils.load_config import load_config \n",
    "from utils.training import metadata_info, configure_optimizer\n",
    "from models import MODELS\n",
    "from trainer import Trainer\n",
    "from data import DiarizationDataset\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "cfg_path = './configs/superior_sepformer.yml'\n",
    "# Loading config file    \n",
    "cfg = load_config(cfg_path)\n",
    "# Load data \n",
    "datamodule = DiarizationDataset(**cfg['data']).setup(stage = 'train')\n",
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}\n",
    "# Load model\n",
    "model_class = MODELS[cfg['trainer']['model_name']]\n",
    "model = model_class(**cfg['model'])\n",
    "# Meta-data\n",
    "metadata_info(model)\n",
    "# TensorBoard\n",
    "writer = TensorBoard(f'tb_logs/{Path(cfg_path).stem}', comment = f\"{cfg['trainer']['ckpt_folder']}\")\n",
    "# Optimizer\n",
    "optimizer = configure_optimizer (cfg, model)\n",
    "# Loss and metrics\n",
    "loss_funcs = {name: PIT(func).to(cfg['trainer']['device']) for name, func in {\"sisnr\": sisnr, \"sdr\": sdr}.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f54396-8cf6-4276-8c46-a586e743bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils.measure_time import measure_time\n",
    "from utils.checkpointer import Checkpointer\n",
    "from utils.training import * \n",
    "\n",
    "class TrainerTest:\n",
    "    def __init__(self, epochs = 100, device='cuda', best_weights = False, checkpointing = False, \n",
    "                 checkpoint_interval = 10, model_name = '', trained_model = './', path_to_weights= './weights', \n",
    "                 ckpt_folder = '', speaker_num = 2, alpha = 0.5, beta = 0.5) -> None:\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.best_weights = best_weights\n",
    "        self.ckpointer = Checkpointer(model_name, path_to_weights, ckpt_folder)\n",
    "        self.checkpointing = checkpointing\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.model_name = model_name\n",
    "        os.makedirs(path_to_weights, exist_ok=True)\n",
    "        self.path_to_weights = path_to_weights\n",
    "        self.ckpt_folder = ckpt_folder\n",
    "        self.speaker_num = speaker_num\n",
    "        self.trained_model = trained_model\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    @measure_time\n",
    "    def fit(self, model, dataloaders, criterions, optimizer, writer) -> None:\n",
    "        model.to(self.device)\n",
    "        start_epoch, min_val_loss, model, optimizer = self.load_pretrained_model(model, optimizer)\n",
    "        epoch_state = EpochState(metrics = criterions, epochs=self.epochs)\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "        for epoch in range(start_epoch, self.epochs):\n",
    "            for phase in ['train', 'valid']:\n",
    "                model.train() if phase == 'train' else model.eval()\n",
    "                dataloader = dataloaders[phase] \n",
    "                for inputs, labels in tqdm(dataloader):\n",
    "                    inputs, labels = inputs.to(self.device), [l.to(self.device) for l in labels]\n",
    "                    '''\n",
    "                    batch = 1 spk = 2 time = 16000\n",
    "                    inputs: [batch, time] \n",
    "                    outputs and labels: [torch.randn(batch, time) for _ in range(spk)]  \n",
    "                    expectention outputs and labels for torch audio-loss: torch.Size([batch, spk, time])\n",
    "                    '''\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        labels = tensify(labels).to(self.device) \n",
    "                        outputs = tensify(outputs).to(self.device) if not isinstance(outputs, torch.Tensor) else outputs.to(self.device)\n",
    "                        losses = {'sisnr': - criterions['sisnr'](outputs, labels),\n",
    "                                  'sdr': - criterions['sdr'](outputs, labels)}  \n",
    "                        loss = self.alpha * losses['sisnr'] + self.beta * losses['sdr']\n",
    "                        if phase == 'train':\n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "                            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "                            optimizer.step()\n",
    "                    epoch_state.update_loss(phase, loss)\n",
    "                    epoch_state.update_metrics(phase, losses)\n",
    "                epoch_loss = epoch_state.compute_loss(phase, len(dataloader))\n",
    "                epoch_metrics = epoch_state.compute_metrics(phase, len(dataloader))\n",
    "                epoch_state.p_output(epoch, phase)\n",
    "                if phase == 'valid':\n",
    "                    if self.best_weights and epoch_loss < min_val_loss:\n",
    "                        min_val_loss = epoch_loss\n",
    "                        self.ckpointer.save_best_weight(model, optimizer, epoch, epoch_state)\n",
    "                    # scheduler.step(epoch_loss)\n",
    "            torch_logger(writer, epoch, epoch_state)\n",
    "            if self.checkpointing and (epoch + 1) % self.checkpoint_interval == 0:\n",
    "                self.ckpointer.save_checkpoint(model, optimizer, epoch, epoch_state)\n",
    "            epoch_state.reset_state()\n",
    "\n",
    "    def load_pretrained_model(self, model, optimizer):\n",
    "        if self.trained_model:\n",
    "            print(f\"Load pretrained mode: {self.trained_model}\", '\\n')\n",
    "            checkpoint = torch.load(self.trained_model, map_location=self.device, weights_only=False)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            return checkpoint['epoch'] + 1, checkpoint['val_loss'] , model, optimizer\n",
    "        else:\n",
    "            return 0, float('inf'), model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde13c68-3234-4d44-8749-831e9d7a65f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b61f418869424b99d7cc052c707430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\b.smadiarov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/900\n",
      "TRAIN, loss: -0.3161 | sisnr: 0.0135 | sdr: -0.7190 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394bba9037894594a38f415ff00b39ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.1635 | sisnr: 0.3019 | sdr: -0.7322 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adca27132214ff9a75188bcaa9d8dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/900\n",
      "TRAIN, loss: -0.7614 | sisnr: -0.3903 | sdr: -1.2151 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789c68f26dbd4f17906e0121e4662b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.2815 | sisnr: 0.1793 | sdr: -0.8447 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6cf89a18d54ea79cbbf4a0dd3fbd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/900\n",
      "TRAIN, loss: -0.8586 | sisnr: -0.4591 | sdr: -1.3470 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2f829fb8434141bda13cc6350d14d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.2960 | sisnr: 0.1696 | sdr: -0.8650 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db75d9812a85422d97b8a41703de40b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/900\n",
      "TRAIN, loss: -0.8920 | sisnr: -0.4923 | sdr: -1.3806 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a933ab2e96b54735bdda4afe3103400d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.3326 | sisnr: 0.1261 | sdr: -0.8933 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f808b1c628545f2a7691df9b6204925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/900\n",
      "TRAIN, loss: -0.9191 | sisnr: -0.4940 | sdr: -1.4387 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7695e0474674d7fa741e5623ec7bd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.3567 | sisnr: 0.1154 | sdr: -0.9337 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d256299f754ac09ce336bfa7b774aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/900\n",
      "TRAIN, loss: -0.9458 | sisnr: -0.5177 | sdr: -1.4691 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e107fb3319cd4a90a07e6aa7fd810d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.3752 | sisnr: 0.0825 | sdr: -0.9348 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e53e26e3ae340c6934f62ab9e130a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/900\n",
      "TRAIN, loss: -0.9531 | sisnr: -0.5374 | sdr: -1.4612 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdbac1c48b0444a8e2b9779602a0b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.3715 | sisnr: 0.1072 | sdr: -0.9566 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddb5d83a75b4d19998f441695e68f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/900\n",
      "TRAIN, loss: -0.9853 | sisnr: -0.5447 | sdr: -1.5238 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a32e2d0309496290dcf8cb57153669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.3959 | sisnr: 0.0999 | sdr: -1.0018 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266928d26afd4fe4aa33d48cf88d4fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/900\n",
      "TRAIN, loss: -1.0064 | sisnr: -0.5465 | sdr: -1.5684 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1125c32d9bab4f4c8f0749f7d0bd5d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4099 | sisnr: 0.0884 | sdr: -1.0190 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4df0dd596c4140931117ff99f211ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/900\n",
      "TRAIN, loss: -1.0274 | sisnr: -0.5580 | sdr: -1.6011 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fcfeda44304ef595e9781033bba2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4200 | sisnr: 0.0773 | sdr: -1.0278 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bbecbb97b3402eb5ca145a5b5fa2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/900\n",
      "TRAIN, loss: -1.0346 | sisnr: -0.5706 | sdr: -1.6017 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2cb0c6078249d59ff4107e7a7ac77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4268 | sisnr: 0.0568 | sdr: -1.0178 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93444d925d54ba0a23f0d3f37ae3136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/900\n",
      "TRAIN, loss: -1.0476 | sisnr: -0.5707 | sdr: -1.6306 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c2cda25ef34b09a1642d537cf946a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4367 | sisnr: 0.0596 | sdr: -1.0434 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40656ec5cd8e4edf82961e994c8744fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/900\n",
      "TRAIN, loss: -1.0607 | sisnr: -0.5788 | sdr: -1.6497 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6967919b71884e978442057a8605e6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4427 | sisnr: 0.0481 | sdr: -1.0425 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e25b10ab1db413582c773213c78cd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/900\n",
      "TRAIN, loss: -1.0694 | sisnr: -0.5810 | sdr: -1.6664 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a0050c6a244b6b845afb2c6ca47ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4393 | sisnr: 0.0611 | sdr: -1.0510 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda408b1e7f848888d0d130bc2bd1e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/900\n",
      "TRAIN, loss: -1.0774 | sisnr: -0.5871 | sdr: -1.6766 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082051d4e8ec49d8983a8089aef881af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4430 | sisnr: 0.0479 | sdr: -1.0431 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07cea99bd174467952610ef644d99ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/900\n",
      "TRAIN, loss: -1.0699 | sisnr: -0.5840 | sdr: -1.6639 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421b0e34c6d54249b21d5852162042c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4397 | sisnr: 0.0498 | sdr: -1.0380 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a4252870664c91afb0e205da7732c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/900\n",
      "TRAIN, loss: -1.0861 | sisnr: -0.5981 | sdr: -1.6827 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ee568de0554fd3825c3a78f7394da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4410 | sisnr: 0.0546 | sdr: -1.0468 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6147bf0c010941c4a7a380eb18408968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/900\n",
      "TRAIN, loss: -1.0960 | sisnr: -0.5993 | sdr: -1.7031 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05193500976434d8668938c425fa286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4376 | sisnr: 0.0637 | sdr: -1.0504 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d00192ecdb4787a49039bb13bb1d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/900\n",
      "TRAIN, loss: -1.0999 | sisnr: -0.6006 | sdr: -1.7101 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451cd06f7a824d698940ae421ab23451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4386 | sisnr: 0.0612 | sdr: -1.0494 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d9d735474940aeb9b23f067dcb60e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/900\n",
      "TRAIN, loss: -1.1075 | sisnr: -0.6091 | sdr: -1.7166 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cdcb6bccee44d8afb097cabcdd1fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4481 | sisnr: 0.0436 | sdr: -1.0490 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b320c934231c482e9d7e8f1b7135459f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/900\n",
      "TRAIN, loss: -1.1129 | sisnr: -0.6118 | sdr: -1.7254 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add0c2ee86974b4e976a47566cc67560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4449 | sisnr: 0.0486 | sdr: -1.0481 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45548d6b173141569cee413b82c08908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/900\n",
      "TRAIN, loss: -1.1169 | sisnr: -0.6136 | sdr: -1.7322 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45f3ae2a66d40f2ab3db31c58315eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4495 | sisnr: 0.0440 | sdr: -1.0526 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb5aa5a42da406fa7174fa2f91cdc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/900\n",
      "TRAIN, loss: -1.1237 | sisnr: -0.6186 | sdr: -1.7410 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b895b05d3554b628acf238b9ae2469b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4488 | sisnr: 0.0434 | sdr: -1.0505 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05010178d4cc4685afbaf5cc0f206c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/900\n",
      "TRAIN, loss: -1.1257 | sisnr: -0.6146 | sdr: -1.7503 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7798565b7440aab7910ae827ed4258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4539 | sisnr: 0.0304 | sdr: -1.0459 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52feaec647440c2a6a64c28582f7bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/900\n",
      "TRAIN, loss: -1.1303 | sisnr: -0.6235 | sdr: -1.7498 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d680742083374275980216af275d9a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4492 | sisnr: 0.0424 | sdr: -1.0501 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcb30687e75443a9ba6018d89502193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/900\n",
      "TRAIN, loss: -1.1349 | sisnr: -0.6257 | sdr: -1.7572 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a9e7d428c84dd2962e9795428ee44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4557 | sisnr: 0.0291 | sdr: -1.0481 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e5007891684096b139023c5cd3930d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/900\n",
      "TRAIN, loss: -1.1394 | sisnr: -0.6288 | sdr: -1.7635 |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e5ddacfc8448688b740eaf9fbe538d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, loss: -0.4580 | sisnr: 0.0256 | sdr: -1.0490 |\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c5afb5f0fa450ebc571b10313fd999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mTrainerTest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mloss_funcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Diploma\\SeparationForKazakhSpeech\\utils\\measure_time.py:15\u001b[0m, in \u001b[0;36mmeasure_time.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     14\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 15\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     16\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     17\u001b[0m     elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[2], line 53\u001b[0m, in \u001b[0;36mTrainerTest.fit\u001b[1;34m(self, model, dataloaders, criterions, optimizer, writer)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 53\u001b[0m     \u001b[43mepoch_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     epoch_state\u001b[38;5;241m.\u001b[39mupdate_metrics(phase, losses)\n\u001b[0;32m     55\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m epoch_state\u001b[38;5;241m.\u001b[39mcompute_loss(phase, \u001b[38;5;28mlen\u001b[39m(dataloader))\n",
      "File \u001b[1;32m~\\Diploma\\SeparationForKazakhSpeech\\utils\\training.py:84\u001b[0m, in \u001b[0;36mEpochState.update_loss\u001b[1;34m(self, phase, loss)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, phase, loss):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m[phase][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "TrainerTest(**cfg['trainer']).fit(model, \n",
    "                                  dataloaders, \n",
    "                                  loss_funcs, \n",
    "                                  optimizer, \n",
    "                                  writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4648881-fab0-4961-adc3-9a94e1b06f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `SuperiorSepformer`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m tuner \u001b[38;5;241m=\u001b[39m Tuner(trainer)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Поиск лучшего learning rate\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m lr_finder \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Оптимальный learning rate\u001b[39;00m\n\u001b[0;32m     12\u001b[0m best_lr \u001b[38;5;241m=\u001b[39m lr_finder\u001b[38;5;241m.\u001b[39msuggestion()\n",
      "File \u001b[1;32mc:\\users\\b.smadiarov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pytorch_lightning\\tuner\\tuning.py:180\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[0;32m    177\u001b[0m lr_finder_callback\u001b[38;5;241m.\u001b[39m_early_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [lr_finder_callback] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;28;01mif\u001b[39;00m cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lr_finder_callback]\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lr_finder_callback\u001b[38;5;241m.\u001b[39moptimal_lr\n",
      "File \u001b[1;32mc:\\users\\b.smadiarov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    500\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m     ckpt_path: Optional[_PATH] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    505\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Runs the full optimization routine.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    530\u001b[0m \n\u001b[0;32m    531\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_unwrap_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    534\u001b[0m     _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n",
      "File \u001b[1;32mc:\\users\\b.smadiarov\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pytorch_lightning\\utilities\\compile.py:111\u001b[0m, in \u001b[0;36m_maybe_unwrap_optimized\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m    110\u001b[0m _check_mixed_imports(model)\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `SuperiorSepformer`"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.tuner.tuning import Tuner\n",
    "\n",
    "# Оборачиваем модель в Trainer\n",
    "trainer = Trainer(accelerator=\"gpu\", max_epochs=1)\n",
    "tuner = Tuner(trainer)\n",
    "\n",
    "# Поиск лучшего learning rate\n",
    "lr_finder = tuner.lr_find(model, train_dataloaders=dataloaders['train'])\n",
    "\n",
    "# Оптимальный learning rate\n",
    "best_lr = lr_finder.suggestion()\n",
    "print(\"Оптимальный learning rate:\", best_lr)\n",
    "\n",
    "# График зависимости loss от lr\n",
    "lr_finder.plot(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e71293a-1d9c-4420-8f1f-7bda7a7679ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam([torch.tensor(1.0, requires_grad=True)], lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Передача обычного числа\n",
    "scheduler.step(0.05)\n",
    "\n",
    "# Передача скалярного тензора\n",
    "metric = torch.tensor(0.05)\n",
    "scheduler.step(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6380b905-afc6-4f0d-98ca-48ab4798c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diarization Error Rate (DER): 0.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def calculate_der(reference, hypothesis, num_speakers):\n",
    "    \"\"\"\n",
    "    Calculate Diarization Error Rate (DER) with permutation alignment.\n",
    "    \n",
    "    Parameters:\n",
    "    - reference: 2D NumPy array (num_segments x num_speakers), binary (1 - speaker active, 0 - not active).\n",
    "    - hypothesis: 2D NumPy array (num_segments x num_speakers), binary (1 - speaker active, 0 - not active).\n",
    "    - num_speakers: Number of speakers.\n",
    "    \n",
    "    Returns:\n",
    "    - der: Diarization Error Rate as a percentage.\n",
    "    \"\"\"\n",
    "    # Check array shapes\n",
    "    assert reference.shape == hypothesis.shape, \"Reference and hypothesis shapes must match!\"\n",
    "    \n",
    "    # Compute confusion matrix (cost matrix)\n",
    "    # Each cell (i, j) is the number of frames where reference speaker i speaks, but hypothesis assigns it to speaker j\n",
    "    cost_matrix = np.zeros((num_speakers, num_speakers))\n",
    "    \n",
    "    for i in range(num_speakers):\n",
    "        for j in range(num_speakers):\n",
    "            # Count mismatches between reference speaker i and hypothesis speaker j\n",
    "            cost_matrix[i, j] = np.sum(np.logical_and(reference[:, i], hypothesis[:, j] == 0)) + \\\n",
    "                                np.sum(np.logical_and(reference[:, i] == 0, hypothesis[:, j]))\n",
    "    \n",
    "    # Use Hungarian algorithm to find the optimal assignment\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    # Apply the optimal assignment to the hypothesis\n",
    "    aligned_hypothesis = np.zeros_like(hypothesis)\n",
    "    for i, j in zip(row_ind, col_ind):\n",
    "        aligned_hypothesis[:, i] = hypothesis[:, j]\n",
    "    \n",
    "    # Calculate DER components\n",
    "    missed_speech = np.sum(np.logical_and(reference == 1, aligned_hypothesis == 0))\n",
    "    false_alarm = np.sum(np.logical_and(reference == 0, aligned_hypothesis == 1))\n",
    "    speaker_confusion = np.sum(np.logical_and(reference == 1, aligned_hypothesis == 1)) - np.sum(reference * aligned_hypothesis)\n",
    "\n",
    "    # Total reference speech time\n",
    "    total_speech_time = np.sum(reference)\n",
    "\n",
    "    # DER formula\n",
    "    der = (missed_speech + false_alarm + speaker_confusion) / total_speech_time\n",
    "    return der * 100\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# Simulated reference and hypothesis (5 time steps, 2 speakers)\n",
    "reference = np.array([\n",
    "    [1, 0],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    [1, 0]\n",
    "])\n",
    "\n",
    "hypothesis = np.array([\n",
    "    [0, 1],  # Hypothesis swapped speakers\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "])\n",
    "\n",
    "r_hypothesis = np.array([\n",
    "    [1, 0],  # Hypothesis swapped speakers\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    [1, 0]\n",
    "])\n",
    "\n",
    "num_speakers = 2\n",
    "der = calculate_der(reference, hypothesis, num_speakers)\n",
    "print(f\"Diarization Error Rate (DER): {der:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6acfff03-5d6b-413e-9fa1-1e98be621a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745865de-d24b-4269-819f-45d646459f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diarization Error Rate (DER): 0.00%\n"
     ]
    }
   ],
   "source": [
    "num_speakers = 2\n",
    "der = calculate_der(reference, r_hypothesis, num_speakers)\n",
    "print(f\"Diarization Error Rate (DER): {der:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488bc8a4-dbac-4681-bf69-688f1bf778c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "793da253-2e36-4f3a-9b96-ca34383dc04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 00:00:00.000 -->  00:00:05.000] _ A\n",
      "[ 00:00:05.000 -->  00:00:10.000] _ B\n",
      "DER = 0.00%\n"
     ]
    }
   ],
   "source": [
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "from pyannote.core import Segment, Annotation\n",
    "\n",
    "# Создаём разметку reference и hypothesis\n",
    "reference = Annotation()\n",
    "reference[Segment(0, 5)] = \"A\"\n",
    "reference[Segment(5, 10)] = \"B\"\n",
    "\n",
    "print(reference)\n",
    "\n",
    "hypothesis = Annotation()\n",
    "hypothesis[Segment(0, 5)] = \"B\"\n",
    "hypothesis[Segment(5, 10)] = \"A\"\n",
    "\n",
    "# Инициализация метрики\n",
    "der = DiarizationErrorRate()\n",
    "\n",
    "# Расчёт DER\n",
    "print(f\"DER = {der(reference, hypothesis):.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427f508-5ed9-44cd-a59c-01451a6bd98f",
   "metadata": {},
   "source": [
    "#### Ligtning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4d907-0a67-42ae-a395-64ac8ee06379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel sepformer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95579434-5dea-48dc-8e4a-98c3ecdf55ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4129abea-37c9-4992-b11c-37fd5312f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "log = \"\"\"Epoch 1/200\n",
    "TRAIN, loss: -1.2249 | sisnr: -0.8991 | sdr: -1.6231 |\n",
    "VALID, loss: -1.5157 | sisnr: -1.2375 | sdr: -1.8557 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 2/200\n",
    "TRAIN, loss: -2.1142 | sisnr: -1.7203 | sdr: -2.5957 |\n",
    "VALID, loss: -2.2680 | sisnr: -1.9200 | sdr: -2.6934 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 3/200\n",
    "TRAIN, loss: -2.8568 | sisnr: -2.4274 | sdr: -3.3815 |\n",
    "VALID, loss: -3.0377 | sisnr: -2.6459 | sdr: -3.5167 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 4/200\n",
    "TRAIN, loss: -3.5181 | sisnr: -3.0665 | sdr: -4.0700 |\n",
    "VALID, loss: -1.9302 | sisnr: -1.6749 | sdr: -2.2423 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 5/200\n",
    "TRAIN, loss: -3.8550 | sisnr: -3.4071 | sdr: -4.4024 |\n",
    "VALID, loss: -3.3887 | sisnr: -3.0413 | sdr: -3.8132 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 6/200\n",
    "TRAIN, loss: -4.1481 | sisnr: -3.7050 | sdr: -4.6898 |\n",
    "VALID, loss: -3.8374 | sisnr: -3.4440 | sdr: -4.3182 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 7/200\n",
    "TRAIN, loss: -4.8348 | sisnr: -4.3830 | sdr: -5.3870 |\n",
    "VALID, loss: -4.7052 | sisnr: -4.2890 | sdr: -5.2138 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 8/200\n",
    "TRAIN, loss: -5.3020 | sisnr: -4.8613 | sdr: -5.8406 |\n",
    "VALID, loss: -5.3846 | sisnr: -4.9074 | sdr: -5.9679 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 9/200\n",
    "TRAIN, loss: -5.7526 | sisnr: -5.3066 | sdr: -6.2976 |\n",
    "VALID, loss: -5.4953 | sisnr: -5.0003 | sdr: -6.1002 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 10/200\n",
    "TRAIN, loss: -6.1007 | sisnr: -5.6617 | sdr: -6.6374 |\n",
    "VALID, loss: -5.9594 | sisnr: -5.4607 | sdr: -6.5691 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 11/200\n",
    "TRAIN, loss: -6.2755 | sisnr: -5.8382 | sdr: -6.8100 |\n",
    "VALID, loss: -4.3845 | sisnr: -3.9057 | sdr: -4.9697 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 12/200\n",
    "TRAIN, loss: -6.6196 | sisnr: -6.1841 | sdr: -7.1518 |\n",
    "VALID, loss: -6.0972 | sisnr: -5.6632 | sdr: -6.6278 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 13/200\n",
    "TRAIN, loss: -6.8672 | sisnr: -6.4381 | sdr: -7.3917 |\n",
    "VALID, loss: -6.1875 | sisnr: -5.7395 | sdr: -6.7350 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 14/200\n",
    "TRAIN, loss: -6.7335 | sisnr: -6.3104 | sdr: -7.2506 |\n",
    "VALID, loss: -5.9863 | sisnr: -5.5417 | sdr: -6.5297 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 15/200\n",
    "TRAIN, loss: -6.9610 | sisnr: -6.5406 | sdr: -7.4748 |\n",
    "VALID, loss: -6.2609 | sisnr: -5.7833 | sdr: -6.8445 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 16/200\n",
    "TRAIN, loss: -6.9797 | sisnr: -6.5590 | sdr: -7.4939 |\n",
    "VALID, loss: -6.7391 | sisnr: -6.3142 | sdr: -7.2583 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 17/200\n",
    "TRAIN, loss: -7.2018 | sisnr: -6.7872 | sdr: -7.7085 |\n",
    "VALID, loss: -7.0540 | sisnr: -6.6068 | sdr: -7.6005 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 18/200\n",
    "TRAIN, loss: -7.0898 | sisnr: -6.6783 | sdr: -7.5928 |\n",
    "VALID, loss: -6.8033 | sisnr: -6.3702 | sdr: -7.3327 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 19/200\n",
    "TRAIN, loss: -7.3717 | sisnr: -6.9605 | sdr: -7.8743 |\n",
    "VALID, loss: -6.8814 | sisnr: -6.4557 | sdr: -7.4017 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 20/200\n",
    "TRAIN, loss: -6.9482 | sisnr: -6.5361 | sdr: -7.4518 |\n",
    "VALID, loss: -6.6264 | sisnr: -6.2075 | sdr: -7.1385 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 21/200\n",
    "TRAIN, loss: -7.2933 | sisnr: -6.8850 | sdr: -7.7924 |\n",
    "VALID, loss: -6.6639 | sisnr: -6.2204 | sdr: -7.2059 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 22/200\n",
    "TRAIN, loss: -6.4923 | sisnr: -6.0802 | sdr: -6.9958 |\n",
    "VALID, loss: -6.2044 | sisnr: -5.7849 | sdr: -6.7172 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 23/200\n",
    "TRAIN, loss: -6.8907 | sisnr: -6.4842 | sdr: -7.3876 |\n",
    "VALID, loss: -6.1372 | sisnr: -5.7200 | sdr: -6.6471 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 24/200\n",
    "TRAIN, loss: -7.1909 | sisnr: -6.7829 | sdr: -7.6894 |\n",
    "VALID, loss: -6.3481 | sisnr: -5.9461 | sdr: -6.8395 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 25/200\n",
    "TRAIN, loss: -7.2353 | sisnr: -6.8292 | sdr: -7.7316 |\n",
    "VALID, loss: -6.5742 | sisnr: -6.1763 | sdr: -7.0606 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 26/200\n",
    "TRAIN, loss: -7.3218 | sisnr: -6.9156 | sdr: -7.8183 |\n",
    "VALID, loss: -6.9426 | sisnr: -6.5027 | sdr: -7.4803 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 27/200\n",
    "TRAIN, loss: -7.4863 | sisnr: -7.0801 | sdr: -7.9826 |\n",
    "VALID, loss: -6.6326 | sisnr: -6.2051 | sdr: -7.1552 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 28/200\n",
    "TRAIN, loss: -7.5068 | sisnr: -7.1005 | sdr: -8.0033 |\n",
    "VALID, loss: -6.6399 | sisnr: -6.2279 | sdr: -7.1434 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 29/200\n",
    "TRAIN, loss: -7.6027 | sisnr: -7.1993 | sdr: -8.0958 |\n",
    "VALID, loss: -7.1478 | sisnr: -6.7268 | sdr: -7.6625 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 30/200\n",
    "TRAIN, loss: -7.2847 | sisnr: -6.8840 | sdr: -7.7743 |\n",
    "VALID, loss: -6.6978 | sisnr: -6.2879 | sdr: -7.1987 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 31/200\n",
    "TRAIN, loss: -6.9961 | sisnr: -6.5969 | sdr: -7.4840 |\n",
    "VALID, loss: -6.5984 | sisnr: -6.2147 | sdr: -7.0673 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 32/200\n",
    "TRAIN, loss: -7.1961 | sisnr: -6.7966 | sdr: -7.6844 |\n",
    "VALID, loss: -7.0008 | sisnr: -6.6004 | sdr: -7.4903 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 33/200\n",
    "TRAIN, loss: -7.6189 | sisnr: -7.2205 | sdr: -8.1058 |\n",
    "VALID, loss: -5.9690 | sisnr: -5.5658 | sdr: -6.4618 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 34/200\n",
    "TRAIN, loss: -7.2954 | sisnr: -6.8985 | sdr: -7.7805 |\n",
    "VALID, loss: -7.1037 | sisnr: -6.6875 | sdr: -7.6125 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 35/200\n",
    "TRAIN, loss: -7.6552 | sisnr: -7.2550 | sdr: -8.1444 |\n",
    "VALID, loss: -6.8849 | sisnr: -6.4699 | sdr: -7.3922 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 36/200\n",
    "TRAIN, loss: -7.7905 | sisnr: -7.3916 | sdr: -8.2781 |\n",
    "VALID, loss: -6.8013 | sisnr: -6.3619 | sdr: -7.3383 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 37/200\n",
    "TRAIN, loss: -7.3751 | sisnr: -6.9751 | sdr: -7.8640 |\n",
    "VALID, loss: -6.4656 | sisnr: -6.0467 | sdr: -6.9776 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 38/200\n",
    "TRAIN, loss: -6.8159 | sisnr: -6.4201 | sdr: -7.2996 |\n",
    "VALID, loss: -6.6676 | sisnr: -6.2465 | sdr: -7.1822 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 39/200\n",
    "TRAIN, loss: -7.1392 | sisnr: -6.7419 | sdr: -7.6247 |\n",
    "VALID, loss: -5.9670 | sisnr: -5.5696 | sdr: -6.4527 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 40/200\n",
    "TRAIN, loss: -6.8061 | sisnr: -6.4092 | sdr: -7.2911 |\n",
    "VALID, loss: -6.6983 | sisnr: -6.2873 | sdr: -7.2008 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 41/200\n",
    "TRAIN, loss: -7.0143 | sisnr: -6.6188 | sdr: -7.4978 |\n",
    "VALID, loss: -6.8773 | sisnr: -6.4693 | sdr: -7.3761 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 42/200\n",
    "TRAIN, loss: -7.1242 | sisnr: -6.7291 | sdr: -7.6072 |\n",
    "VALID, loss: -6.0281 | sisnr: -5.5868 | sdr: -6.5673 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 43/200\n",
    "TRAIN, loss: -6.9717 | sisnr: -6.5765 | sdr: -7.4546 |\n",
    "VALID, loss: -6.5418 | sisnr: -6.1353 | sdr: -7.0387 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 44/200\n",
    "TRAIN, loss: -7.0707 | sisnr: -6.6763 | sdr: -7.5527 |\n",
    "VALID, loss: -5.9960 | sisnr: -5.6278 | sdr: -6.4460 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 45/200\n",
    "TRAIN, loss: -7.0334 | sisnr: -6.6415 | sdr: -7.5124 |\n",
    "VALID, loss: -6.8909 | sisnr: -6.4769 | sdr: -7.3970 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 46/200\n",
    "TRAIN, loss: -7.2047 | sisnr: -6.8106 | sdr: -7.6865 |\n",
    "VALID, loss: -6.2342 | sisnr: -5.8445 | sdr: -6.7105 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 47/200\n",
    "TRAIN, loss: -7.3047 | sisnr: -6.9177 | sdr: -7.7778 |\n",
    "VALID, loss: -6.0995 | sisnr: -5.7139 | sdr: -6.5708 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 48/200\n",
    "TRAIN, loss: -7.3005 | sisnr: -6.9063 | sdr: -7.7822 |\n",
    "VALID, loss: -6.4764 | sisnr: -6.0901 | sdr: -6.9485 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 49/200\n",
    "TRAIN, loss: -6.9525 | sisnr: -6.5609 | sdr: -7.4312 |\n",
    "VALID, loss: -5.4282 | sisnr: -5.0278 | sdr: -5.9175 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 50/200\n",
    "TRAIN, loss: -6.8184 | sisnr: -6.4258 | sdr: -7.2983 |\n",
    "VALID, loss: -5.9082 | sisnr: -5.5213 | sdr: -6.3811 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 51/200\n",
    "TRAIN, loss: -6.7916 | sisnr: -6.3992 | sdr: -7.2712 |\n",
    "VALID, loss: -6.0780 | sisnr: -5.6737 | sdr: -6.5721 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 52/200\n",
    "TRAIN, loss: -7.0879 | sisnr: -6.6968 | sdr: -7.5660 |\n",
    "VALID, loss: -6.5364 | sisnr: -6.1449 | sdr: -7.0149 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 53/200\n",
    "TRAIN, loss: -7.3054 | sisnr: -6.9127 | sdr: -7.7855 |\n",
    "VALID, loss: -6.5629 | sisnr: -6.1583 | sdr: -7.0575 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 54/200\n",
    "TRAIN, loss: -7.3261 | sisnr: -6.9349 | sdr: -7.8043 |\n",
    "VALID, loss: -6.4022 | sisnr: -5.9659 | sdr: -6.9355 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 55/200\n",
    "TRAIN, loss: -7.3064 | sisnr: -6.9130 | sdr: -7.7872 |\n",
    "VALID, loss: -6.0837 | sisnr: -5.6259 | sdr: -6.6434 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 56/200\n",
    "TRAIN, loss: -6.8455 | sisnr: -6.4537 | sdr: -7.3243 |\n",
    "VALID, loss: -6.5540 | sisnr: -6.1593 | sdr: -7.0363 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 57/200\n",
    "TRAIN, loss: -7.1631 | sisnr: -6.7705 | sdr: -7.6429 |\n",
    "VALID, loss: -6.5300 | sisnr: -6.1304 | sdr: -7.0184 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 58/200\n",
    "TRAIN, loss: -7.2546 | sisnr: -6.8677 | sdr: -7.7275 |\n",
    "VALID, loss: -6.5930 | sisnr: -6.2129 | sdr: -7.0575 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 59/200\n",
    "TRAIN, loss: -7.2764 | sisnr: -6.8894 | sdr: -7.7494 |\n",
    "VALID, loss: -6.0057 | sisnr: -5.6039 | sdr: -6.4967 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 60/200\n",
    "TRAIN, loss: -7.2165 | sisnr: -6.8264 | sdr: -7.6933 |\n",
    "VALID, loss: -6.3453 | sisnr: -5.9623 | sdr: -6.8135 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 61/200\n",
    "TRAIN, loss: -7.2592 | sisnr: -6.8715 | sdr: -7.7331 |\n",
    "VALID, loss: -6.6821 | sisnr: -6.2732 | sdr: -7.1818 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 62/200\n",
    "TRAIN, loss: -7.3158 | sisnr: -6.9278 | sdr: -7.7902 |\n",
    "VALID, loss: -6.4328 | sisnr: -6.0531 | sdr: -6.8969 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 63/200\n",
    "TRAIN, loss: -7.4211 | sisnr: -7.0336 | sdr: -7.8946 |\n",
    "VALID, loss: -6.3253 | sisnr: -5.9053 | sdr: -6.8387 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 64/200\n",
    "TRAIN, loss: -7.6945 | sisnr: -7.3038 | sdr: -8.1722 |\n",
    "VALID, loss: -7.0419 | sisnr: -6.6333 | sdr: -7.5412 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 65/200\n",
    "TRAIN, loss: -7.2459 | sisnr: -6.8547 | sdr: -7.7239 |\n",
    "VALID, loss: -6.8539 | sisnr: -6.4524 | sdr: -7.3446 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 66/200\n",
    "TRAIN, loss: -7.5394 | sisnr: -7.1479 | sdr: -8.0179 |\n",
    "VALID, loss: -6.8390 | sisnr: -6.4283 | sdr: -7.3409 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 67/200\n",
    "TRAIN, loss: -7.5297 | sisnr: -7.1386 | sdr: -8.0079 |\n",
    "VALID, loss: -6.8479 | sisnr: -6.4400 | sdr: -7.3465 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 68/200\n",
    "TRAIN, loss: -7.6717 | sisnr: -7.2822 | sdr: -8.1478 |\n",
    "VALID, loss: -6.9980 | sisnr: -6.5962 | sdr: -7.4892 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 69/200\n",
    "TRAIN, loss: -7.4379 | sisnr: -7.0484 | sdr: -7.9140 |\n",
    "VALID, loss: -6.8589 | sisnr: -6.4631 | sdr: -7.3427 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 70/200\n",
    "TRAIN, loss: -7.7183 | sisnr: -7.3332 | sdr: -8.1890 |\n",
    "VALID, loss: -6.7430 | sisnr: -6.3451 | sdr: -7.2293 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 71/200\n",
    "TRAIN, loss: -7.0969 | sisnr: -6.7109 | sdr: -7.5686 |\n",
    "VALID, loss: -6.6540 | sisnr: -6.2768 | sdr: -7.1150 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 72/200\n",
    "TRAIN, loss: -7.6091 | sisnr: -7.2234 | sdr: -8.0805 |\n",
    "VALID, loss: -6.9562 | sisnr: -6.5730 | sdr: -7.4246 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 73/200\n",
    "TRAIN, loss: -7.7031 | sisnr: -7.3183 | sdr: -8.1734 |\n",
    "VALID, loss: -7.0216 | sisnr: -6.6318 | sdr: -7.4980 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 74/200\n",
    "TRAIN, loss: -7.6321 | sisnr: -7.2469 | sdr: -8.1028 |\n",
    "VALID, loss: -7.0983 | sisnr: -6.6833 | sdr: -7.6055 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 75/200\n",
    "TRAIN, loss: -7.8932 | sisnr: -7.5075 | sdr: -8.3645 |\n",
    "VALID, loss: -6.9401 | sisnr: -6.5485 | sdr: -7.4189 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 76/200\n",
    "TRAIN, loss: -7.6400 | sisnr: -7.2543 | sdr: -8.1113 |\n",
    "VALID, loss: -7.0621 | sisnr: -6.6855 | sdr: -7.5224 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 77/200\n",
    "TRAIN, loss: -7.5100 | sisnr: -7.1234 | sdr: -7.9826 |\n",
    "TRAIN, loss: -7.5100 | sisnr: -7.1234 | sdr: -7.9826 |\n",
    "VALID, loss: -6.0354 | sisnr: -5.6314 | sdr: -6.5293 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 78/200\n",
    "TRAIN, loss: -7.6612 | sisnr: -7.2725 | sdr: -8.1363 |\n",
    "VALID, loss: -5.9898 | sisnr: -5.6051 | sdr: -6.4599 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 79/200\n",
    "TRAIN, loss: -7.7874 | sisnr: -7.4005 | sdr: -8.2603 |\n",
    "VALID, loss: -6.7497 | sisnr: -6.3433 | sdr: -7.2463 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 80/200\n",
    "TRAIN, loss: -7.6624 | sisnr: -7.2790 | sdr: -8.1311 |\n",
    "VALID, loss: -6.9575 | sisnr: -6.5531 | sdr: -7.4518 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 81/200\n",
    "TRAIN, loss: -7.8274 | sisnr: -7.4419 | sdr: -8.2985 |\n",
    "VALID, loss: -6.7766 | sisnr: -6.3641 | sdr: -7.2808 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 82/200\n",
    "TRAIN, loss: -7.7192 | sisnr: -7.3342 | sdr: -8.1896 |\n",
    "VALID, loss: -6.9869 | sisnr: -6.5718 | sdr: -7.4942 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 83/200\n",
    "TRAIN, loss: -7.8552 | sisnr: -7.4725 | sdr: -8.3229 |\n",
    "VALID, loss: -7.0355 | sisnr: -6.6367 | sdr: -7.5228 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 84/200\n",
    "TRAIN, loss: -7.9783 | sisnr: -7.5960 | sdr: -8.4457 |\n",
    "VALID, loss: -7.0789 | sisnr: -6.6744 | sdr: -7.5732 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 85/200\n",
    "TRAIN, loss: -7.9747 | sisnr: -7.5897 | sdr: -8.4453 |\n",
    "VALID, loss: -6.7453 | sisnr: -6.3609 | sdr: -7.2151 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 86/200\n",
    "TRAIN, loss: -7.9535 | sisnr: -7.5678 | sdr: -8.4248 |\n",
    "VALID, loss: -7.3051 | sisnr: -6.8965 | sdr: -7.8045 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 87/200\n",
    "TRAIN, loss: -7.6815 | sisnr: -7.2987 | sdr: -8.1494 |\n",
    "VALID, loss: -7.0143 | sisnr: -6.6212 | sdr: -7.4948 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 88/200\n",
    "TRAIN, loss: -8.0541 | sisnr: -7.6712 | sdr: -8.5221 |\n",
    "VALID, loss: -7.2238 | sisnr: -6.8435 | sdr: -7.6885 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 89/200\n",
    "TRAIN, loss: -7.9671 | sisnr: -7.5838 | sdr: -8.4356 |\n",
    "VALID, loss: -6.6541 | sisnr: -6.2596 | sdr: -7.1362 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 90/200\n",
    "TRAIN, loss: -8.1201 | sisnr: -7.7383 | sdr: -8.5868 |\n",
    "VALID, loss: -6.0590 | sisnr: -5.6782 | sdr: -6.5244 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 91/200\n",
    "TRAIN, loss: -8.0352 | sisnr: -7.6509 | sdr: -8.5050 |\n",
    "VALID, loss: -7.0325 | sisnr: -6.6073 | sdr: -7.5522 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 92/200\n",
    "TRAIN, loss: -8.1673 | sisnr: -7.7834 | sdr: -8.6366 |\n",
    "VALID, loss: -7.1992 | sisnr: -6.7821 | sdr: -7.7090 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 93/200\n",
    "TRAIN, loss: -8.2769 | sisnr: -7.8938 | sdr: -8.7452 |\n",
    "VALID, loss: -7.2632 | sisnr: -6.8655 | sdr: -7.7494 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 94/200\n",
    "TRAIN, loss: -8.1995 | sisnr: -7.8177 | sdr: -8.6660 |\n",
    "VALID, loss: -6.5032 | sisnr: -6.1030 | sdr: -6.9922 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 95/200\n",
    "TRAIN, loss: -8.2936 | sisnr: -7.9100 | sdr: -8.7624 |\n",
    "VALID, loss: -6.7545 | sisnr: -6.3291 | sdr: -7.2743 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 96/200\n",
    "TRAIN, loss: -8.2408 | sisnr: -7.8563 | sdr: -8.7107 |\n",
    "VALID, loss: -6.2832 | sisnr: -5.8946 | sdr: -6.7581 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 97/200\n",
    "TRAIN, loss: -7.9001 | sisnr: -7.5181 | sdr: -8.3670 |\n",
    "VALID, loss: -6.9372 | sisnr: -6.5408 | sdr: -7.4218 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 98/200\n",
    "TRAIN, loss: -7.9848 | sisnr: -7.6017 | sdr: -8.4531 |\n",
    "VALID, loss: -6.8823 | sisnr: -6.4932 | sdr: -7.3579 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 99/200\n",
    "TRAIN, loss: -8.0258 | sisnr: -7.6422 | sdr: -8.4946 |\n",
    "VALID, loss: -5.8188 | sisnr: -5.3969 | sdr: -6.3345 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 100/200\n",
    "TRAIN, loss: -7.6943 | sisnr: -7.3112 | sdr: -8.1624 |\n",
    "VALID, loss: -6.6938 | sisnr: -6.2715 | sdr: -7.2100 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 101/200\n",
    "TRAIN, loss: -7.6996 | sisnr: -7.3164 | sdr: -8.1679 |\n",
    "VALID, loss: -6.3166 | sisnr: -5.9113 | sdr: -6.8120 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 102/200\n",
    "TRAIN, loss: -7.1173 | sisnr: -6.7295 | sdr: -7.5913 |\n",
    "VALID, loss: -5.8846 | sisnr: -5.4347 | sdr: -6.4345 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 103/200\n",
    "TRAIN, loss: -7.3787 | sisnr: -6.9937 | sdr: -7.8493 |\n",
    "VALID, loss: -6.3741 | sisnr: -5.9597 | sdr: -6.8808 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 104/200\n",
    "TRAIN, loss: -6.9537 | sisnr: -6.5728 | sdr: -7.4191 |\n",
    "VALID, loss: -6.3376 | sisnr: -5.9371 | sdr: -6.8271 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 105/200\n",
    "TRAIN, loss: -7.2484 | sisnr: -6.8671 | sdr: -7.7145 |\n",
    "VALID, loss: -6.7083 | sisnr: -6.3107 | sdr: -7.1942 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 106/200\n",
    "TRAIN, loss: -7.3348 | sisnr: -6.9560 | sdr: -7.7979 |\n",
    "VALID, loss: -6.4565 | sisnr: -6.0385 | sdr: -6.9675 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 107/200\n",
    "TRAIN, loss: -7.7559 | sisnr: -7.3724 | sdr: -8.2246 |\n",
    "VALID, loss: -6.0838 | sisnr: -5.6240 | sdr: -6.6459 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 108/200\n",
    "TRAIN, loss: -7.1114 | sisnr: -6.7297 | sdr: -7.5779 |\n",
    "VALID, loss: -6.5929 | sisnr: -6.1884 | sdr: -7.0873 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 109/200\n",
    "TRAIN, loss: -7.3454 | sisnr: -6.9632 | sdr: -7.8125 |\n",
    "VALID, loss: -6.8711 | sisnr: -6.4629 | sdr: -7.3700 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 110/200\n",
    "TRAIN, loss: -7.5979 | sisnr: -7.2150 | sdr: -8.0660 |\n",
    "VALID, loss: -6.2920 | sisnr: -5.8743 | sdr: -6.8025 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 111/200\n",
    "TRAIN, loss: -7.6962 | sisnr: -7.3106 | sdr: -8.1675 |\n",
    "VALID, loss: -6.7929 | sisnr: -6.3969 | sdr: -7.2769 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 112/200\n",
    "TRAIN, loss: -7.2625 | sisnr: -6.8755 | sdr: -7.7355 |\n",
    "VALID, loss: -6.3301 | sisnr: -5.8886 | sdr: -6.8696 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 113/200\n",
    "TRAIN, loss: -7.9230 | sisnr: -7.5383 | sdr: -8.3932 |\n",
    "VALID, loss: -6.7914 | sisnr: -6.3652 | sdr: -7.3122 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 114/200\n",
    "TRAIN, loss: -7.8121 | sisnr: -7.4290 | sdr: -8.2804 |\n",
    "VALID, loss: -6.3975 | sisnr: -5.9889 | sdr: -6.8968 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 115/200\n",
    "TRAIN, loss: -7.6951 | sisnr: -7.3125 | sdr: -8.1626 |\n",
    "VALID, loss: -5.9344 | sisnr: -5.5220 | sdr: -6.4384 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 116/200\n",
    "TRAIN, loss: -7.7713 | sisnr: -7.3847 | sdr: -8.2439 |\n",
    "VALID, loss: -6.8493 | sisnr: -6.4312 | sdr: -7.3603 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 117/200\n",
    "TRAIN, loss: -7.8300 | sisnr: -7.4492 | sdr: -8.2953 |\n",
    "VALID, loss: -6.5118 | sisnr: -6.0818 | sdr: -7.0373 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 118/200\n",
    "TRAIN, loss: -7.9795 | sisnr: -7.5934 | sdr: -8.4514 |\n",
    "VALID, loss: -6.7924 | sisnr: -6.3916 | sdr: -7.2823 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 119/200\n",
    "TRAIN, loss: -8.0084 | sisnr: -7.6226 | sdr: -8.4799 |\n",
    "VALID, loss: -6.6711 | sisnr: -6.2539 | sdr: -7.1811 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 120/200\n",
    "TRAIN, loss: -7.8534 | sisnr: -7.4683 | sdr: -8.3241 |\n",
    "VALID, loss: -6.4449 | sisnr: -6.0283 | sdr: -6.9540 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 121/200\n",
    "TRAIN, loss: -8.0260 | sisnr: -7.6428 | sdr: -8.4943 |\n",
    "VALID, loss: -6.8365 | sisnr: -6.4296 | sdr: -7.3339 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 122/200\n",
    "TRAIN, loss: -7.8491 | sisnr: -7.4638 | sdr: -8.3202 |\n",
    "VALID, loss: -5.9352 | sisnr: -5.5267 | sdr: -6.4345 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 123/200\n",
    "TRAIN, loss: -7.8827 | sisnr: -7.4982 | sdr: -8.3528 |\n",
    "VALID, loss: -6.9906 | sisnr: -6.5833 | sdr: -7.4885 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 124/200\n",
    "TRAIN, loss: -7.3348 | sisnr: -6.9511 | sdr: -7.8038 |\n",
    "VALID, loss: -6.3729 | sisnr: -5.9697 | sdr: -6.8657 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 125/200\n",
    "TRAIN, loss: -7.6897 | sisnr: -7.3034 | sdr: -8.1617 |\n",
    "VALID, loss: -6.1440 | sisnr: -5.7435 | sdr: -6.6335 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 126/200\n",
    "TRAIN, loss: -7.3681 | sisnr: -6.9853 | sdr: -7.8360 |\n",
    "VALID, loss: -6.0060 | sisnr: -5.6043 | sdr: -6.4970 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 127/200\n",
    "TRAIN, loss: -7.5552 | sisnr: -7.1711 | sdr: -8.0245 |\n",
    "VALID, loss: -5.7100 | sisnr: -5.2787 | sdr: -6.2371 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 128/200\n",
    "TRAIN, loss: -7.5386 | sisnr: -7.1554 | sdr: -8.0069 |\n",
    "VALID, loss: -5.9418 | sisnr: -5.5494 | sdr: -6.4213 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 129/200\n",
    "TRAIN, loss: -7.7473 | sisnr: -7.3618 | sdr: -8.2185 |\n",
    "VALID, loss: -6.1912 | sisnr: -5.7833 | sdr: -6.6897 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 130/200\n",
    "TRAIN, loss: -7.6480 | sisnr: -7.2639 | sdr: -8.1175 |\n",
    "VALID, loss: -6.4299 | sisnr: -6.0130 | sdr: -6.9395 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 131/200\n",
    "TRAIN, loss: -7.7825 | sisnr: -7.3999 | sdr: -8.2501 |\n",
    "VALID, loss: -6.6271 | sisnr: -6.2172 | sdr: -7.1281 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 132/200\n",
    "TRAIN, loss: -7.7215 | sisnr: -7.3357 | sdr: -8.1929 |\n",
    "VALID, loss: -6.2635 | sisnr: -5.8425 | sdr: -6.7781 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 133/200\n",
    "TRAIN, loss: -7.9973 | sisnr: -7.6103 | sdr: -8.4703 |\n",
    "VALID, loss: -6.0068 | sisnr: -5.5926 | sdr: -6.5129 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 134/200\n",
    "TRAIN, loss: -8.1496 | sisnr: -7.7636 | sdr: -8.6214 |\n",
    "VALID, loss: -6.6899 | sisnr: -6.2729 | sdr: -7.1995 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 135/200\n",
    "TRAIN, loss: -8.1855 | sisnr: -7.7990 | sdr: -8.6579 |\n",
    "VALID, loss: -6.7587 | sisnr: -6.3518 | sdr: -7.2560 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 136/200\n",
    "TRAIN, loss: -7.9097 | sisnr: -7.5250 | sdr: -8.3800 |\n",
    "VALID, loss: -6.7963 | sisnr: -6.3830 | sdr: -7.3015 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 137/200\n",
    "TRAIN, loss: -8.0404 | sisnr: -7.6522 | sdr: -8.5149 |\n",
    "VALID, loss: -6.7986 | sisnr: -6.3898 | sdr: -7.2983 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 138/200\n",
    "TRAIN, loss: -8.3324 | sisnr: -7.9441 | sdr: -8.8070 |\n",
    "VALID, loss: -6.8945 | sisnr: -6.4916 | sdr: -7.3870 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 139/200\n",
    "TRAIN, loss: -8.1466 | sisnr: -7.7608 | sdr: -8.6181 |\n",
    "VALID, loss: -6.5352 | sisnr: -6.1392 | sdr: -7.0192 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 140/200\n",
    "TRAIN, loss: -7.9028 | sisnr: -7.5165 | sdr: -8.3750 |\n",
    "VALID, loss: -6.6968 | sisnr: -6.2977 | sdr: -7.1845 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 141/200\n",
    "TRAIN, loss: -7.8107 | sisnr: -7.4245 | sdr: -8.2827 |\n",
    "VALID, loss: -6.8545 | sisnr: -6.4426 | sdr: -7.3580 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 142/200\n",
    "TRAIN, loss: -8.0738 | sisnr: -7.6862 | sdr: -8.5476 |\n",
    "VALID, loss: -6.4748 | sisnr: -6.0490 | sdr: -6.9951 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 143/200\n",
    "TRAIN, loss: -7.9945 | sisnr: -7.6057 | sdr: -8.4697 |\n",
    "VALID, loss: -6.5958 | sisnr: -6.1803 | sdr: -7.1036 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 144/200\n",
    "TRAIN, loss: -8.0198 | sisnr: -7.6299 | sdr: -8.4963 |\n",
    "VALID, loss: -6.4638 | sisnr: -6.0384 | sdr: -6.9837 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 145/200\n",
    "TRAIN, loss: -7.9533 | sisnr: -7.5647 | sdr: -8.4283 |\n",
    "VALID, loss: -6.8246 | sisnr: -6.4188 | sdr: -7.3206 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 146/200\n",
    "TRAIN, loss: -7.8598 | sisnr: -7.4764 | sdr: -8.3284 |\n",
    "VALID, loss: -6.7586 | sisnr: -6.3251 | sdr: -7.2885 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 147/200\n",
    "TRAIN, loss: -7.9914 | sisnr: -7.6009 | sdr: -8.4687 |\n",
    "VALID, loss: -6.2392 | sisnr: -5.8401 | sdr: -6.7271 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 148/200\n",
    "TRAIN, loss: -7.6684 | sisnr: -7.2773 | sdr: -8.1465 |\n",
    "VALID, loss: -6.6775 | sisnr: -6.2730 | sdr: -7.1719 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 149/200\n",
    "TRAIN, loss: -8.2045 | sisnr: -7.8134 | sdr: -8.6825 |\n",
    "VALID, loss: -6.2450 | sisnr: -5.8413 | sdr: -6.7384 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 150/200\n",
    "TRAIN, loss: -8.4640 | sisnr: -8.0738 | sdr: -8.9408 |\n",
    "VALID, loss: -6.9657 | sisnr: -6.5629 | sdr: -7.4579 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 151/200\n",
    "TRAIN, loss: -8.6822 | sisnr: -8.2884 | sdr: -9.1636 |\n",
    "VALID, loss: -6.5461 | sisnr: -6.1303 | sdr: -7.0544 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 152/200\n",
    "TRAIN, loss: -8.7924 | sisnr: -8.4005 | sdr: -9.2715 |\n",
    "VALID, loss: -7.0991 | sisnr: -6.6759 | sdr: -7.6164 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 153/200\n",
    "TRAIN, loss: -8.7358 | sisnr: -8.3453 | sdr: -9.2132 |\n",
    "VALID, loss: -6.7246 | sisnr: -6.3066 | sdr: -7.2356 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 154/200\n",
    "TRAIN, loss: -8.5136 | sisnr: -8.1239 | sdr: -8.9899 |\n",
    "VALID, loss: -6.1220 | sisnr: -5.6851 | sdr: -6.6559 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 155/200\n",
    "TRAIN, loss: -8.7194 | sisnr: -8.3283 | sdr: -9.1974 |\n",
    "VALID, loss: -6.2451 | sisnr: -5.8485 | sdr: -6.7299 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 156/200\n",
    "TRAIN, loss: -8.7451 | sisnr: -8.3554 | sdr: -9.2215 |\n",
    "VALID, loss: -7.2331 | sisnr: -6.8170 | sdr: -7.7418 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 157/200\n",
    "TRAIN, loss: -9.0217 | sisnr: -8.6279 | sdr: -9.5029 |\n",
    "VALID, loss: -7.3077 | sisnr: -6.8876 | sdr: -7.8212 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 158/200\n",
    "TRAIN, loss: -8.5982 | sisnr: -8.2055 | sdr: -9.0782 |\n",
    "VALID, loss: -6.9922 | sisnr: -6.5698 | sdr: -7.5084 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 159/200\n",
    "TRAIN, loss: -7.9755 | sisnr: -7.5833 | sdr: -8.4549 |\n",
    "VALID, loss: -7.0194 | sisnr: -6.5965 | sdr: -7.5362 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 160/200\n",
    "TRAIN, loss: -8.3852 | sisnr: -7.9940 | sdr: -8.8632 |\n",
    "VALID, loss: -7.0532 | sisnr: -6.6289 | sdr: -7.5718 |\n",
    "--------------------------------------------------------------------\n",
    "Epoch 161/200\n",
    "TRAIN, loss: -8.7058 | sisnr: -8.3137 | sdr: -9.1850 |\n",
    "VALID, loss: -6.7074 | sisnr: -6.2923 | sdr: -7.2147 |\n",
    "--------------------------------------------------------------------\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a19640-8bf9-4eba-ad85-d5266e90cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logger(logs, stage, index=0, csv_filename = './'):\n",
    "    lines = log.split(\"\\n\")\n",
    "    data = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith(\"Epoch\"):\n",
    "            epoch = int(line.split()[1].split('/')[0]) - 1\n",
    "        elif line.startswith(stage):\n",
    "            val = float(line.split(\"|\")[index].split(\":\")[1].strip())\n",
    "            data.append([1735105736, epoch, val])\n",
    "            \n",
    "    with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Wall time\", \"Step\", \"Value\"])  \n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f\"Данные успешно сохранены в файл {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55958abd-fd36-4f18-8ff4-2fe68731c152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно сохранены в файл ./checkpoints/dualpathrnn/train_sisnr_160_epoch.csv\n"
     ]
    }
   ],
   "source": [
    "_logger(log, \n",
    "        \"TRAIN\", \n",
    "        index = 1,\n",
    "        csv_filename = \"./checkpoints/dualpathrnn/train_sisnr_160_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a912c16-09a2-447a-972a-69c65822474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно сохранены в файл ./checkpoints/dualpathrnn/train_sdr_160_epoch.csv\n"
     ]
    }
   ],
   "source": [
    "_logger(log, \n",
    "        \"TRAIN\", \n",
    "        index = 2,\n",
    "        csv_filename = \"./checkpoints/dualpathrnn/train_sdr_160_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408a1b73-0118-40bf-a7f1-dc1d70ada02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно сохранены в файл ./checkpoints/dualpathrnn/valid_sisnr_160_epoch.csv\n"
     ]
    }
   ],
   "source": [
    "_logger(log, \n",
    "        \"VALID\", \n",
    "        index = 1,\n",
    "        csv_filename = \"./checkpoints/dualpathrnn/valid_sisnr_160_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bac075c5-7043-45c2-845b-6556ab08b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно сохранены в файл ./checkpoints/dualpathrnn/valid_sdr_160_epoch.csv\n"
     ]
    }
   ],
   "source": [
    "_logger(log, \n",
    "        \"VALID\", \n",
    "        index = 2,\n",
    "        csv_filename = \"./checkpoints/dualpathrnn/valid_sdr_160_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df03bb9-cf10-4439-bc54-33fd4c24527a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
