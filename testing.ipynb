{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b639a159-037f-4ff8-9352-10d60c2f33fd",
   "metadata": {},
   "source": [
    "#### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875ee058-0d14-40bd-b05c-212a0e1dd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from typing import Optional\n",
    "import argparse\n",
    "\n",
    "from utils.funtctional import handle_scp\n",
    "from utils.data_processing import read_wav\n",
    "from utils.load_config import load_config \n",
    "\n",
    "EPS = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35300f6-aa62-4640-a78f-58a865a53dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mix_dir': './mixed_data/',\n",
       " 'ref_dirs': './targets/',\n",
       " 'train_split': 0.8,\n",
       " 'val_split': 0.1,\n",
       " 'num_workers': 1,\n",
       " 'batch_size': 1,\n",
       " 'sample_rate': 16000,\n",
       " 'chunk_size': 32000,\n",
       " 'least_size': 16000,\n",
       " 'seed': 42}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg, ckpt_folder = load_config('./config/train_rnn.yml')\n",
    "cfg['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4e47f7-121d-4ca2-80c1-a2b01f9da6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from glob import glob\n",
    "import torch as th\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "from typing import Optional, List\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "class AudioDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, mix_paths: List[str], ref_paths: List[List[str]], \n",
    "                 sample_rate: int = 8000, chunk_size: int = 32000, least_size: int = 16000):\n",
    "        super().__init__()\n",
    "        self.mix_audio = self._load_audio(mix_paths, sample_rate, chunk_size, least_size)\n",
    "        self.ref_audio = [self._load_audio(ref, sample_rate, chunk_size, least_size) for ref in ref_paths]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mix_audio)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mix = self.mix_audio[idx]\n",
    "        refs = [ref[idx] for ref in self.ref_audio]\n",
    "        return mix, refs\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_audio(paths: List[str], sample_rate: int, chunk_size: int, least_size: int):\n",
    "        audios = []\n",
    "        for path in paths:\n",
    "            audio, sr = torchaudio.load(path)\n",
    "            if sr != sample_rate:\n",
    "                raise RuntimeError(f\"Sample rate mismatch: {sr} vs {sample_rate}\")\n",
    "\n",
    "            # Pad or chunk the audio\n",
    "            if audio.shape[-1] < least_size:\n",
    "                continue\n",
    "            if least_size <= audio.shape[-1] < chunk_size:\n",
    "                pad_size = chunk_size - audio.shape[-1]\n",
    "                audios.append(F.pad(audio, (0, pad_size), mode='constant'))\n",
    "            else:\n",
    "                start = 0\n",
    "                while start + chunk_size <= audio.shape[-1]:\n",
    "                    audios.append(audio[:, start:start + chunk_size])\n",
    "                    start += least_size\n",
    "        return audios\n",
    "\n",
    "\n",
    "class AudioDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, mix_dir: str, ref_dirs: List[str], batch_size: int = 128, \n",
    "                 train_split: float = 0.8, val_split: float = 0.1, sample_rate: int = 8000, \n",
    "                 chunk_size: int = 32000, least_size: int = 16000, num_workers: int = 4, seed: int = 42):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self.least_size = least_size\n",
    "        self.num_workers = num_workers\n",
    "        self.seed = seed\n",
    "\n",
    "        self.mix_paths = glob(os.path.join(mix_dir, \"*.wav\"))\n",
    "        self.ref_paths = [glob(os.path.join(ref_dir, \"*.wav\")) for ref_dir in ref_dirs]\n",
    "\n",
    "        random.seed(seed)\n",
    "        random.shuffle(self.mix_paths)\n",
    "\n",
    "        total = len(self.mix_paths)\n",
    "        train_end = int(total * train_split)\n",
    "        val_end = train_end + int(total * val_split)\n",
    "\n",
    "        self.train_paths = self.mix_paths[:train_end]\n",
    "        self.val_paths = self.mix_paths[train_end:val_end]\n",
    "        self.test_paths = self.mix_paths[val_end:]\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        self.train_dataset = AudioDataset(self.train_paths, self.ref_paths, \n",
    "                                          self.sample_rate, self.chunk_size, self.least_size)\n",
    "        self.val_dataset = AudioDataset(self.val_paths, self.ref_paths, \n",
    "                                        self.sample_rate, self.chunk_size, self.least_size)\n",
    "        self.test_dataset = AudioDataset(self.test_paths, self.ref_paths, \n",
    "                                         self.sample_rate, self.chunk_size, self.least_size)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, \n",
    "                                        shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.val_dataset, batch_size=self.batch_size, \n",
    "                                        shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.test_dataset, batch_size=self.batch_size, \n",
    "                                        shuffle=False, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b9e804-b59b-414d-87d7-7821d1df20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = AudioDataModule(**cfg['data'])\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b9c4eb7-8a7f-4ad8-bfa6-ddf1fbdd3a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataloader, val_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mmake_dataloader\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: train_dataloader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m: val_dataloader}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = make_dataloader(**cfg['data'])\n",
    "dataloaders = {'train': train_dataloader, 'valid': val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ca598-f521-4572-875f-d673c059d20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa3513-d0b9-4f29-aff4-9fb5d3819fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
