{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14234ca6-8b70-4324-9b78-5081273407d2",
   "metadata": {},
   "source": [
    "#### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc69ca4-37f6-4aa3-be38-7222b2822758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from glob import glob\n",
    "import torch as th\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "from typing import Optional, List\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd \n",
    "from tqdm.notebook import tqdm \n",
    "import numpy as np\n",
    "\n",
    "from utils.measure_time import measure_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4e47f7-121d-4ca2-80c1-a2b01f9da6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, mix_file_paths: List[str], ref_file_paths: List[List[str]], \n",
    "                 sr: int = 8000, chunk_size: int = 32000, least_size: int = 16000):\n",
    "        super().__init__()\n",
    "        self.mix_audio = []\n",
    "        self.ref_audio = []\n",
    "        k = len(ref_file_paths[1])\n",
    "        for mix_path, ref_paths in zip(mix_file_paths, ref_file_paths):\n",
    "            common_len = ref_paths[0]\n",
    "            chunked_mix = self._load_audio(mix_path, sr, common_len, chunk_size, least_size)\n",
    "            if not chunked_mix: continue\n",
    "            ref_audio_chunks = []    \n",
    "            for ref_path in ref_paths[1]:\n",
    "                res = self._load_audio(ref_path, sr, common_len, chunk_size, least_size)\n",
    "                ref_audio_chunks.append(res)\n",
    "            if k != len(ref_audio_chunks): continue\n",
    "            self.mix_audio.append(chunked_mix)\n",
    "            self.ref_audio.append(ref_audio_chunks)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mix_audio)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mix = self.mix_audio[idx][0]\n",
    "        refs = self.ref_audio[idx][0]\n",
    "        # refs = [ref[idx] for ref in self.ref_audio]\n",
    "        return mix, refs\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_audio(path:str, sr: int, common_len: int, chunk_size: int, least_size: int):\n",
    "        audio, _sr = torchaudio.load(path)\n",
    "        audio = audio[:, :common_len]\n",
    "        if _sr != sr: raise RuntimeError(f\"Sample rate mismatch: {_sr} vs {sr}\")\n",
    "        if audio.shape[-1] < least_size: return []\n",
    "        audio_chunks = []\n",
    "        if least_size < audio.shape[-1] < chunk_size:\n",
    "            pad_size = chunk_size - audio.shape[-1]\n",
    "            audio_chunks.append(F.pad(audio, (0, pad_size), mode='constant'))\n",
    "        else:\n",
    "            start = 0\n",
    "            while start + chunk_size <= audio.shape[-1]:\n",
    "                audio = audio.squeeze() # warning\n",
    "                audio_chunks.append(audio[start:start + chunk_size])\n",
    "                start += least_size\n",
    "        return audio_chunks \n",
    "\n",
    "class ExtendedAudioDataset(AudioDataset):\n",
    "    def __getitems__(self, item):\n",
    "        return self.__getitem__(item)\n",
    "\n",
    "class AudioDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str, csv_file:bool = False, total_percent: float = 0.1, train_percent:float = 0.8, valid_percent:float = 0.1, \n",
    "                 test_percent: float = 0.1, num_workers: int = 4, batch_size: int = 512, pin_memory = False, seed: int = 42, \n",
    "                 sample_rate: int = 8000, chunk_size: int = 32000, least_size: int = 16000):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.sr = sample_rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self.least_size = least_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.seed = seed\n",
    "        self._set_seed(seed)\n",
    "        self.g = th.Generator()\n",
    "        self.g.manual_seed(seed)\n",
    "        self.mix_paths = []\n",
    "        self.ref_paths = []\n",
    "        \n",
    "        if csv_file:\n",
    "            full_df = pd.read_csv(data_dir)\n",
    "            for _, row in full_df.iterrows():\n",
    "                self.mix_paths.append (row.iloc[0])\n",
    "                self.ref_paths.append([row.iloc[1], sorted([row[column] for column in full_df.columns[2:]])])\n",
    "        else: \n",
    "            mixed_list = glob(os.path.join(data_dir, \"*.flac\"))\n",
    "            for mx in tqdm(mixed_list):\n",
    "                mx = mx.replace('\\\\', '/')\n",
    "                self.mix_paths.append (mx)\n",
    "                mx_df = pd.read_csv(mx.replace('flac', 'csv'))\n",
    "                f_real = [mx_df.iloc[0], sorted([mx_df.iloc[0][column] for column in mx_df.columns[2:]])] # THERE IS BAG need to fixed \n",
    "                self.ref_paths.append(f_real)\n",
    "\n",
    "        self.mix_paths = self.mix_paths[:int(len(self.mix_paths) * total_percent)]\n",
    "        self.ref_paths = self.ref_paths[:int(len(self.ref_paths) * total_percent)]\n",
    "        random.shuffle(self.mix_paths)\n",
    "        assert math.isclose(train_percent + valid_percent + test_percent, 1.0, rel_tol=1e-9), \"Sum doesnt equal to 1\" \n",
    "        self.train_len = int(len(self.mix_paths) * train_percent)\n",
    "        self.valid_len = int(len(self.mix_paths) * valid_percent)\n",
    "        self.test_len = int(len(self.mix_paths) * test_percent)\n",
    "\n",
    "    @measure_time\n",
    "    def setup(self, stage = 'train'):\n",
    "        assert stage in ['train', 'eval'], \"Invalid stage\"\n",
    "        \n",
    "        if stage == 'train': \n",
    "            self.train_dataset = AudioDataset(self.mix_paths[:self.train_len], \n",
    "                                              self.ref_paths[:self.train_len], \n",
    "                                              sr = self.sr, \n",
    "                                              chunk_size = self.chunk_size, \n",
    "                                              least_size = self.least_size)\n",
    "            print(f\"Size of training set: {len(self.train_dataset)}\")\n",
    "            \n",
    "            self.val_dataset = AudioDataset(self.mix_paths[self.train_len:self.train_len + self.valid_len], \n",
    "                                            self.ref_paths[self.train_len:self.train_len + self.valid_len], \n",
    "                                            sr = self.sr, \n",
    "                                            chunk_size = self.chunk_size, \n",
    "                                            least_size = self.least_size) \n",
    "            print(f\"Size of validation set: {len(self.val_dataset)}\")\n",
    "            \n",
    "        if stage == 'eval':\n",
    "            self.test_dataset = AudioDataset(self.mix_paths[self.train_len + self.valid_len:], \n",
    "                                             self.ref_paths[self.train_len + self.valid_len:], \n",
    "                                             sr = self.sr, \n",
    "                                             chunk_size = self.chunk_size, \n",
    "                                             least_size = self.least_size)\n",
    "            print(f\"Size of test set: {len(self.test_dataset)}\")\n",
    "\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.train_dataset, \n",
    "                                        batch_size=self.batch_size, \n",
    "                                        pin_memory = self.pin_memory,\n",
    "                                        shuffle=True, \n",
    "                                        num_workers=self.num_workers,\n",
    "                                        worker_init_fn=self.seed_worker,\n",
    "                                        generator=self.g)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.val_dataset, \n",
    "                                        batch_size=self.batch_size, \n",
    "                                        pin_memory = self.pin_memory,\n",
    "                                        shuffle=False, \n",
    "                                        num_workers=self.num_workers,\n",
    "                                        worker_init_fn=self.seed_worker,\n",
    "                                        generator=self.g)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.test_dataset, \n",
    "                                        batch_size=self.batch_size,\n",
    "                                        pin_memory = self.pin_memory, \n",
    "                                        shuffle=False, \n",
    "                                        num_workers=self.num_workers, \n",
    "                                        worker_init_fn=self.seed_worker,\n",
    "                                        generator=self.g)\n",
    "\n",
    "    def _set_seed(self, seed: int):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        th.manual_seed(seed)\n",
    "        th.cuda.manual_seed_all(seed)\n",
    "\n",
    "    def seed_worker(self, worker_id):\n",
    "        worker_seed = th.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fd87ed-9d94-4344-bac5-49e2010bba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from utils.load_config import load_config  \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-p\", \"--hparams\", type=str, default=\"./configs/train_rnn.yml\", help=\"hparams config file\")\n",
    "args, unknown = parser.parse_known_args()  # Игнорирует нераспознанные аргументы\n",
    "cfg = load_config(args.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e7b78ba-5022-4d94-9e9b-063b623b634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_dir': 'F:/ISSAI_KSC2_unpacked/DIHARD_DATA_INFO/CONCATED_DFS_tts=2000_k_2.csv',\n",
       " 'csv_file': True,\n",
       " 'total_percent': 1.0,\n",
       " 'train_percent': 0.8,\n",
       " 'valid_percent': 0.1,\n",
       " 'test_percent': 0.1,\n",
       " 'num_workers': 0,\n",
       " 'batch_size': 1,\n",
       " 'pin_memory': True,\n",
       " 'seed': 42,\n",
       " 'sample_rate': 16000,\n",
       " 'chunk_size': 32000,\n",
       " 'least_size': 16000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b9e804-b59b-414d-87d7-7821d1df20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 800\n",
      "Size of validation set: 100\n",
      "Elapsed time 'setup': 00:00:02.23\n"
     ]
    }
   ],
   "source": [
    "datamodule = AudioDataModule(**cfg['data'])\n",
    "datamodule.setup(stage = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8888a7-e1c6-4545-8b6c-a0a6de82e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "554598ec-535b-4159-baa4-128aac54fe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0005,  0.0007,  0.0008,  ..., -0.0423, -0.0381, -0.0295]])\n",
      "[tensor([[0.0052, 0.0042, 0.0026,  ..., 0.0020, 0.0026, 0.0033]])]\n"
     ]
    }
   ],
   "source": [
    "# Получение первого батча данных из DataLoader\n",
    "dataloader = dataloaders['train'] \n",
    "sample_mix, sample_refs = next(iter(dataloader))  # Используем iter и next для доступа к данным\n",
    "print(sample_mix)\n",
    "print(sample_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8200bc-8f82-457a-8b37-3d53234c5aa5",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0a2ddf6-576a-499d-ab6a-8374bfa655df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchmetrics\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter as TensorBoard\n",
    "\n",
    "from utils.load_config import load_config \n",
    "from utils.training import metadata_info, configure_optimizer\n",
    "from utils.measure_time import measure_time\n",
    "from utils.training import p_output_log \n",
    "from models.model_rnn import Dual_RNN_model\n",
    "from losses import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ad7ed87-deee-47da-a710-8c2c223abaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aefc9f9b-5102-417f-a0f8-44c4fd09120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_channels': 256,\n",
       " 'out_channels': 64,\n",
       " 'hidden_channels': 128,\n",
       " 'kernel_size': 2,\n",
       " 'rnn_type': 'LSTM',\n",
       " 'norm': 'ln',\n",
       " 'dropout': 0,\n",
       " 'bidirectional': True,\n",
       " 'num_layers': 6,\n",
       " 'K': 250,\n",
       " 'speaker_num': 2}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d0153db-beee-46aa-82a6-c53d5ae69a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dual_RNN_model(**cfg['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ae9ec3c-2f76-42d1-bc27-2bf95a5a058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parametrs: 2633729\n",
      "Size of model: 10.05 MB, in float32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata_info(model)\n",
    "writer = TensorBoard(f'tb_logs/{Path(args.hparams).stem}', comment = f\"{cfg['trainer']['ckpt_folder']}\")\n",
    "optimizer = configure_optimizer (cfg, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "826a4cc1-28bd-4edc-b62e-9c2df6909ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_epochs': 100,\n",
       " 'device': 'cuda',\n",
       " 'best_weights': False,\n",
       " 'checkpointing': False,\n",
       " 'checkpoint_interval': 5,\n",
       " 'model_name': 'Dual_Path_RNN',\n",
       " 'path_to_weights': './weights',\n",
       " 'ckpt_folder': './checkpoints/train_rnn',\n",
       " 'speaker_num': 2,\n",
       " 'resume': False}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['trainer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bacfda33-fbca-4143-aba9-4a8825730c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from itertools import permutations\n",
    "\n",
    "def sisnr(x, s, eps=1e-8):\n",
    "    \"\"\"\n",
    "    calculate training loss\n",
    "    input:\n",
    "          x: separated signal, N x S tensor\n",
    "          s: reference signal, N x S tensor\n",
    "    Return:\n",
    "          sisnr: N tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def l2norm(mat, keepdim=False):\n",
    "        return torch.norm(mat, dim=-1, keepdim=keepdim)\n",
    "\n",
    "    if x.shape != s.shape:\n",
    "        raise RuntimeError(\n",
    "            \"Dimention mismatch when calculate si-snr, {} vs {}\".format(\n",
    "                x.shape, s.shape))\n",
    "    x_zm = x - torch.mean(x, dim=-1, keepdim=True)\n",
    "    s_zm = s - torch.mean(s, dim=-1, keepdim=True)\n",
    "    t = torch.sum(\n",
    "        x_zm * s_zm, dim=-1,\n",
    "        keepdim=True) * s_zm / (l2norm(s_zm, keepdim=True)**2 + eps)\n",
    "    return 20 * torch.log10(eps + l2norm(t) / (l2norm(x_zm - t) + eps))\n",
    "\n",
    "\n",
    "def CustomLoss(ests, egs):\n",
    "    # spks x n x S\n",
    "    refs = egs\n",
    "    num_spks = len(refs)\n",
    "\n",
    "    def sisnr_loss(permute):\n",
    "        print(f\"Length of ests: {len(ests)}, Length of refs: {len(refs)}\")\n",
    "        print(f\"Permute: {permute}\")\n",
    "        # for one permute\n",
    "        return sum([sisnr(ests[s], refs[t]) for s, t in enumerate(permute)]) / len(permute)  # average the value\n",
    "\n",
    "    # P x N\n",
    "    N = egs[0].size(0)\n",
    "    sisnr_mat = torch.stack(\n",
    "        [sisnr_loss(p) for p in permutations(range(num_spks))])\n",
    "    max_perutt, _ = torch.max(sisnr_mat, dim=0)\n",
    "    # si-snr\n",
    "    return -torch.sum(max_perutt) / N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f345f0f1-77f8-4096-8ce4-8d4425b9a502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ests: 2, Length of refs: 2\n",
      "Permute: (0, 1)\n",
      "Length of ests: 2, Length of refs: 2\n",
      "Permute: (1, 0)\n",
      "Custom Loss: -9.563565254211426\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Размерность: N = 3 (батч), S = 8 (длина сигнала)\n",
    "# Предсказанные сигналы (2 говорящих)\n",
    "ests = [\n",
    "    torch.tensor([\n",
    "        [0.5, 0.6, 0.8, 0.9, 1.0, 0.7, 0.3, 0.2],\n",
    "        [0.3, 0.4, 0.6, 0.8, 0.5, 0.3, 0.1, 0.0],\n",
    "        [0.2, 0.1, 0.3, 0.5, 0.7, 0.6, 0.4, 0.2]\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        [0.1, 0.2, 0.4, 0.6, 0.7, 0.8, 0.9, 0.5],\n",
    "        [0.0, 0.1, 0.2, 0.3, 0.5, 0.7, 0.9, 0.8],\n",
    "        [0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0, 0.1]\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Эталонные сигналы (2 говорящих)\n",
    "egs = [\n",
    "    torch.tensor([\n",
    "        [0.6, 0.7, 0.9, 1.0, 0.8, 0.6, 0.4, 0.3],\n",
    "        [0.2, 0.3, 0.5, 0.7, 0.6, 0.4, 0.2, 0.1],\n",
    "        [0.1, 0.2, 0.4, 0.6, 0.8, 0.7, 0.5, 0.3]\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        [0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 0.6],\n",
    "        [0.1, 0.2, 0.4, 0.5, 0.6, 0.8, 0.9, 0.7],\n",
    "        [0.5, 0.4, 0.3, 0.2, 0.1, 0.0, 0.1, 0.2]\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Рассчитаем функцию потерь\n",
    "loss = CustomLoss(ests, egs)\n",
    "print(f\"Custom Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e234a9b7-be8d-4d9b-93ea-52ab0cc68a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ests: 2, Length of refs: 2\n",
      "Permute: (0, 1)\n",
      "Length of ests: 2, Length of refs: 2\n",
      "Permute: (1, 0)\n",
      "Custom Loss (ideal case): -148.2356414794922\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Эталонные сигналы (2 говорящих, батч из 3, длина сигнала 8)\n",
    "egs = [\n",
    "    torch.tensor([\n",
    "        [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.8, 0.6],\n",
    "        [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "        [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        [0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0, 0.1],\n",
    "        [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Предсказанные сигналы, идентичные эталонным\n",
    "ests = [\n",
    "    torch.tensor([\n",
    "        [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.8, 0.6],\n",
    "        [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "        [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "        [0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0, 0.1],\n",
    "        [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Рассчитаем функцию потерь\n",
    "loss = CustomLoss(ests, egs)\n",
    "print(f\"Custom Loss (ideal case): {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b0fb967f-42fc-447e-9594-9eb06e71caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source tensor([[[2, 1, 2,  ..., 0, 0, 0],\n",
      "         [2, 1, 2,  ..., 0, 0, 0]]])\n",
      "estimate_source tensor([[[0, 0, 2,  ..., 0, 0, 0],\n",
      "         [2, 3, 1,  ..., 0, 0, 0]]])\n",
      "source_lengths tensor([32000, 31999], dtype=torch.int32)\n",
      "loss tensor(43.5560)\n",
      "max_snr tensor([[-43.5560],\n",
      "        [-43.5560]])\n",
      "reorder_estimate_source tensor([[[0, 0, 2,  ..., 0, 0, 0],\n",
      "         [2, 3, 1,  ..., 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "\n",
    "class MixerMSE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(MixerMSE, self).__init__()\n",
    "\n",
    "        self.criterion1 = nn.MSELoss()\n",
    "\n",
    "        self.criterion2 = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, target):\n",
    "\n",
    "        loss = self.criterion1(x[0, 0, :], target[0, 0, :]) + self.criterion2(x[0, 1, :], target[0, 1, :])\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def cal_loss_no(source, estimate_source, source_lengths):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            source: [B, C, T], B is batch size,C is the number of speaker,T is the length of each batch\n",
    "            estimate_source: [B, C, T]\n",
    "            source_lengths: [B]\n",
    "    \"\"\"\n",
    "    max_snr, perms, max_snr_idx = cal_si_snr(source, estimate_source, source_lengths)\n",
    "\n",
    "    loss = 0 - torch.mean(max_snr)\n",
    "\n",
    "    reorder_estimate_source = reorder_source(estimate_source, perms, max_snr_idx)\n",
    "\n",
    "    return loss, max_snr, estimate_source, reorder_estimate_source\n",
    "\n",
    "\n",
    "def cal_si_snr(source, estimate_source, source_lengths):\n",
    "    \"\"\"\n",
    "        Calculate SI-SNR with PIT training.\n",
    "\n",
    "        Args:\n",
    "            source: [B, C, T], B is batch size\n",
    "            estimate_source: [B, C, T]\n",
    "            source_lengths: [B], each item is between [0, T]\n",
    "    \"\"\"\n",
    "    assert source.size() == estimate_source.size()\n",
    "    B, C, T = source.size()  # get all parameters\n",
    "    # mask padding position along T\n",
    "    mask = get_mask(source, source_lengths)\n",
    "    estimate_source *= mask\n",
    "\n",
    "    # Step 1. Zero-mean norm\n",
    "    num_samples = source_lengths.view(-1, 1, 1).float()  # [B, 1, 1]\n",
    "    mean_target = torch.sum(source, dim=2, keepdim=True) / num_samples\n",
    "    mean_estimate = torch.sum(estimate_source, dim=2, keepdim=True) / num_samples\n",
    "    zero_mean_target = source - mean_target\n",
    "    zero_mean_estimate = estimate_source - mean_estimate\n",
    "    # mask padding position along T\n",
    "    zero_mean_target *= mask\n",
    "    zero_mean_estimate *= mask\n",
    "\n",
    "    # Step 2. SI-SNR with PIT\n",
    "    # reshape to use broadcast\n",
    "    s_target = torch.unsqueeze(zero_mean_target, dim=1)  # [B, 1, C, T]\n",
    "    s_estimate = torch.unsqueeze(zero_mean_estimate, dim=2)  # [B, C, 1, T]\n",
    "    # print(\"s_target.type()\", s_target.type(), s_estimate.type())\n",
    "    # s_target = <s', s>s / ||s||^2\n",
    "    pair_wise_dot = torch.sum(s_estimate * s_target, dim=3, keepdim=True)  # [B, C, C, 1]\n",
    "    s_target_energy = torch.sum(s_target ** 2, dim=3, keepdim=True) + EPS  # [B, 1, C, 1]\n",
    "    pair_wise_proj = pair_wise_dot * s_target / s_target_energy  # [B, C, C, T]\n",
    "    # print(\"pair_wise_dot.type()\", pair_wise_dot.type(), \"s_target_energy.type()\", s_target_energy.type())\n",
    "    # print(\"pair_wise_proj.type()\", pair_wise_proj.type())\n",
    "    # e_noise = s' - s_target\n",
    "    e_noise = s_estimate - pair_wise_proj  # [B, C, C, T]\n",
    "    # print(e_noise.type())\n",
    "    # SI-SNR = 10 * log_10(||s_target||^2 / ||e_noise||^2)\n",
    "    pair_wise_si_snr = torch.sum(pair_wise_proj ** 2, dim=3) / (torch.sum(e_noise ** 2, dim=3) + EPS)\n",
    "    pair_wise_si_snr = 10 * torch.log10(pair_wise_si_snr + EPS) # [B, C, C]\n",
    "    # print(\"pair_wise_si_snr\",pair_wise_si_snr.type())\n",
    "\n",
    "    # Get max_snr of each utterance\n",
    "    # permutations, [C!, C]\n",
    "    perms = source.new_tensor(list(permutations(range(C))), dtype=torch.long)\n",
    "    # one-hot, [C!, C, C]\n",
    "    index = torch.unsqueeze(perms, 2)\n",
    "    # print(index.type())\n",
    "    # 如果不加.type(torch.float),perms-one-hot为long，在执行torch.einsum时会报错\n",
    "    perms_one_hot = torch.unsqueeze(perms, dim=0).type(torch.float)\n",
    "    # print(\"perms_one_hot\", perms_one_hot.type())\n",
    "    # [B, C!] <- [B, C, C] einsum [C!, C, C], SI-SNR sum of each permutation\n",
    "    snr_set = torch.einsum('bij,pij->bp', [pair_wise_si_snr, perms_one_hot])\n",
    "    # print(\"snr_set.type()\",snr_set.type())\n",
    "    max_snr_idx = torch.argmax(snr_set, dim=1)  # [B]\n",
    "    # max_snr = torch.gather(snr_set, 1, max_snr_idx.view(-1, 1))  # [B, 1]\n",
    "    max_snr, _ = torch.max(snr_set, dim=1, keepdim=True)\n",
    "    max_snr /= C\n",
    "\n",
    "    return max_snr, perms, max_snr_idx\n",
    "\n",
    "\n",
    "def cal_loss_pit(source, estimate_source, source_lengths):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            source: [B, C, T], B is batch size,C is the number of speaker,T is the length of each batch\n",
    "            estimate_source: [B, C, T]\n",
    "            source_lengths: [B]\n",
    "    \"\"\"\n",
    "    max_snr, perms, max_snr_idx = cal_si_snr_with_pit(source, estimate_source, source_lengths)\n",
    "\n",
    "    loss = 0 - torch.mean(max_snr)\n",
    "\n",
    "    reorder_estimate_source = reorder_source(estimate_source, perms, max_snr_idx)\n",
    "\n",
    "    return loss, max_snr, estimate_source, reorder_estimate_source\n",
    "\n",
    "\n",
    "def cal_si_snr_with_pit(source, estimate_source, source_lengths):\n",
    "    \"\"\"\n",
    "        Calculate SI-SNR with PIT training.\n",
    "\n",
    "        Args:\n",
    "            source: [B, C, T], B is batch size\n",
    "            estimate_source: [B, C, T]\n",
    "            source_lengths: [B], each item is between [0, T]\n",
    "    \"\"\"\n",
    "    assert source.size() == estimate_source.size()\n",
    "    B, C, T = source.size()  # get all parameters\n",
    "    # mask padding position along T\n",
    "    mask = get_mask(source, source_lengths)\n",
    "    estimate_source *= mask\n",
    "\n",
    "    # Step 1. Zero-mean norm\n",
    "    num_samples = source_lengths.view(-1, 1, 1).float()  # [B, 1, 1]\n",
    "    mean_target = torch.sum(source, dim=2, keepdim=True) / num_samples\n",
    "    mean_estimate = torch.sum(estimate_source, dim=2, keepdim=True) / num_samples\n",
    "    zero_mean_target = source - mean_target\n",
    "    zero_mean_estimate = estimate_source - mean_estimate\n",
    "    # mask padding position along T\n",
    "    zero_mean_target *= mask\n",
    "    zero_mean_estimate *= mask\n",
    "\n",
    "    # Step 2. SI-SNR with PIT\n",
    "    # reshape to use broadcast\n",
    "    s_target = torch.unsqueeze(zero_mean_target, dim=1)  # [B, 1, C, T]\n",
    "    s_estimate = torch.unsqueeze(zero_mean_estimate, dim=2)  # [B, C, 1, T]\n",
    "    # print(\"s_target.type()\", s_target.type(), s_estimate.type())\n",
    "    # s_target = <s', s>s / ||s||^2\n",
    "    pair_wise_dot = torch.sum(s_estimate * s_target, dim=3, keepdim=True)  # [B, C, C, 1]\n",
    "    s_target_energy = torch.sum(s_target ** 2, dim=3, keepdim=True) + EPS  # [B, 1, C, 1]\n",
    "    pair_wise_proj = pair_wise_dot * s_target / s_target_energy  # [B, C, C, T]\n",
    "    # print(\"pair_wise_dot.type()\", pair_wise_dot.type(), \"s_target_energy.type()\", s_target_energy.type())\n",
    "    # print(\"pair_wise_proj.type()\", pair_wise_proj.type())\n",
    "    # e_noise = s' - s_target\n",
    "    e_noise = s_estimate - pair_wise_proj  # [B, C, C, T]\n",
    "    # print(e_noise.type())\n",
    "    # SI-SNR = 10 * log_10(||s_target||^2 / ||e_noise||^2)\n",
    "    pair_wise_si_snr = torch.sum(pair_wise_proj ** 2, dim=3) / (torch.sum(e_noise ** 2, dim=3) + EPS)\n",
    "    pair_wise_si_snr = 10 * torch.log10(pair_wise_si_snr + EPS) # [B, C, C]\n",
    "    # print(\"pair_wise_si_snr\",pair_wise_si_snr.type())\n",
    "\n",
    "\n",
    "    # Get max_snr of each utterance\n",
    "    # permutations, [C!, C] \n",
    "    perms = source.new_tensor(list(permutations(range(C))), dtype=torch.long)\n",
    "    # one-hot, [C!, C, C]\n",
    "    index = torch.unsqueeze(perms, 2)\n",
    "    # print(index.type())\n",
    "    # 如果不加.type(torch.float),perms-one-hot为long，在执行torch.einsum时会报错\n",
    "    perms_one_hot = source.new_zeros((*perms.size(), C)).scatter_(2, index, 1).type(torch.float)\n",
    "    # print(\"perms_one_hot\", perms_one_hot.type())\n",
    "    # [B, C!] <- [B, C, C] einsum [C!, C, C], SI-SNR sum of each permutation\n",
    "    snr_set = torch.einsum('bij,pij->bp', [pair_wise_si_snr, perms_one_hot])\n",
    "    # print(\"snr_set.type()\",snr_set.type())\n",
    "    max_snr_idx = torch.argmax(snr_set, dim=1)  # [B]\n",
    "    # max_snr = torch.gather(snr_set, 1, max_snr_idx.view(-1, 1))  # [B, 1]\n",
    "    max_snr, _ = torch.max(snr_set, dim=1, keepdim=True)\n",
    "    max_snr /= C\n",
    "    return max_snr, perms, max_snr_idx\n",
    "\n",
    "\n",
    "def reorder_source(source, perms, max_snr_idx):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            source: [B, C, T]\n",
    "            perms: [C!, C], permutations\n",
    "            max_snr_idx: [B], each item is between [0, C!)\n",
    "        Returns:\n",
    "            reorder_source: [B, C, T]\n",
    "    \"\"\"\n",
    "    B, C, *_ = source.size()\n",
    "    # [B, C], permutation whose SI-SNR is max of each utterance\n",
    "    # for each utterance, reorder estimate source according this permutation\n",
    "    max_snr_perm = torch.index_select(perms, dim=0, index=max_snr_idx)\n",
    "    # print('max_snr_perm', max_snr_perm)\n",
    "    # maybe use torch.gather()/index_select()/scatter() to impl this?\n",
    "    reorder_source = torch.zeros_like(source)\n",
    "\n",
    "    for b in range(B):\n",
    "        for c in range(C):\n",
    "            reorder_source[b, c] = source[b, max_snr_perm[b][c]]\n",
    "\n",
    "    return reorder_source\n",
    "\n",
    "\n",
    "def get_mask(source, source_lengths):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            source: [B, C, T]\n",
    "            source_lengths: [B]\n",
    "        Returns:\n",
    "            mask: [B, 1, T]\n",
    "    \"\"\"\n",
    "    B, _, T = source.size()\n",
    "\n",
    "    mask = source.new_ones((B, 1, T))\n",
    "\n",
    "    for i in range(B):\n",
    "        mask[i, :, source_lengths[i]:] = 0\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(123)\n",
    "    B, C, T = 1, 2, 32000\n",
    "    # fake data\n",
    "    source = torch.randint(4, (B, C, T))\n",
    "    estimate_source = torch.randint(4, (B, C, T))\n",
    "    source[0, :, -3:] = 0\n",
    "    estimate_source[0, :, -3:] = 0\n",
    "    source_lengths = torch.FloatTensor([T, T - 1]).type(torch.int)\n",
    "    print('source', source)\n",
    "    print('estimate_source', estimate_source)\n",
    "    print('source_lengths', source_lengths)\n",
    "\n",
    "    loss, max_snr, estimate_source, reorder_estimate_source = cal_loss_no(source, estimate_source, source_lengths)\n",
    "    print('loss', loss)\n",
    "    print('max_snr', max_snr)\n",
    "    print('reorder_estimate_source', reorder_estimate_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64fe7bda-8dc8-4dca-be9e-a19f800e16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, num_epochs = 100, device='cuda', best_weights = False, checkpointing = False, \n",
    "                 checkpoint_interval = 10, model_name = '', path_to_weights= './weights', ckpt_folder = '',\n",
    "                 speaker_num = 2, resume = False) -> None:\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.best_weights = best_weights\n",
    "        self.checkpointing = checkpointing\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.model_name = model_name\n",
    "        os.makedirs(path_to_weights, exist_ok=True)\n",
    "        self.path_to_weights = path_to_weights\n",
    "        self.ckpt_folder = ckpt_folder\n",
    "        self.speaker_num = speaker_num\n",
    "        self.resume = resume\n",
    "\n",
    "    @measure_time\n",
    "    def fit(self, model, dataloaders, criterion, optimizer, writer) -> None:\n",
    "        model.to(self.device)\n",
    "        min_val_loss = float('inf')\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for phase in ['train', 'valid']:\n",
    "                model.train() if phase == 'train' else model.eval()\n",
    "                dataloader = dataloaders[phase] \n",
    "                running_loss = 0.0\n",
    "                for inputs, labels in tqdm(dataloader):\n",
    "                    inputs, labels = inputs.to(self.device), [label.to(self.device) for label in labels]\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        if phase == 'train':\n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                break\n",
    "                epoch_loss = running_loss / len(dataloader.dataset)\n",
    "                print(epoch_loss)\n",
    "                # p_output_log(self.num_epochs, epoch, epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35f98e52-44e3-47e1-a921-676219548905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe7abd31d54281bceeac05e293182f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ests: 2, Length of refs: 1\n",
      "Permute: (0,)\n",
      "Length of ests: 2, Length of refs: 4\n",
      "Permute: (0, 1, 2, 3)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCustomLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Diploma\\DualPathRNN\\utils\\measure_time.py:15\u001b[0m, in \u001b[0;36mmeasure_time.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     14\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 15\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     16\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     17\u001b[0m     elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[57], line 30\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, dataloaders, criterion, optimizer, writer)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     29\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m---> 30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     32\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[1;32mIn[56], line 43\u001b[0m, in \u001b[0;36mCustomLoss\u001b[1;34m(ests, egs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# P x N\u001b[39;00m\n\u001b[0;32m     41\u001b[0m N \u001b[38;5;241m=\u001b[39m egs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     42\u001b[0m sisnr_mat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m---> 43\u001b[0m     [sisnr_loss(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m permutations(\u001b[38;5;28mrange\u001b[39m(num_spks))])\n\u001b[0;32m     44\u001b[0m max_perutt, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(sisnr_mat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# si-snr\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[56], line 43\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# P x N\u001b[39;00m\n\u001b[0;32m     41\u001b[0m N \u001b[38;5;241m=\u001b[39m egs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     42\u001b[0m sisnr_mat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m---> 43\u001b[0m     [\u001b[43msisnr_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m permutations(\u001b[38;5;28mrange\u001b[39m(num_spks))])\n\u001b[0;32m     44\u001b[0m max_perutt, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(sisnr_mat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# si-snr\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[56], line 38\u001b[0m, in \u001b[0;36mCustomLoss.<locals>.sisnr_loss\u001b[1;34m(permute)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermute: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpermute\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# for one permute\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([sisnr(ests[s], refs[t]) \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(permute)]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(permute)\n",
      "Cell \u001b[1;32mIn[56], line 38\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermute: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpermute\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# for one permute\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([sisnr(\u001b[43mests\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m, refs[t]) \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(permute)]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(permute)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "Trainer(**cfg['trainer']).fit(model, dataloaders, CustomLoss, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9361a9-56fb-4ab8-b9b5-952a976138d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
