{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14234ca6-8b70-4324-9b78-5081273407d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc69ca4-37f6-4aa3-be38-7222b2822758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from glob import glob\n",
    "import torch as th\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "from typing import Optional, List\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd \n",
    "from tqdm.notebook import tqdm \n",
    "import numpy as np\n",
    "\n",
    "from utils.measure_time import measure_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fd87ed-9d94-4344-bac5-49e2010bba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from utils.load_config import load_config  \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-p\", \"--hparams\", type=str, default=\"./configs/train_rnn.yml\", help=\"hparams config file\")\n",
    "args, unknown = parser.parse_known_args()  # Игнорирует нераспознанные аргументы\n",
    "cfg = load_config(args.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b9e804-b59b-414d-87d7-7821d1df20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 420\n",
      "Size of validation set: 63\n",
      "Elapsed time 'setup': 00:00:02.20\n"
     ]
    }
   ],
   "source": [
    "datamodule = AudioDataModule(**cfg['data']).setup(stage = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8888a7-e1c6-4545-8b6c-a0a6de82e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554598ec-535b-4159-baa4-128aac54fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение первого батча данных из DataLoader\n",
    "dataloader = dataloaders['train'] \n",
    "sample_mix, sample_refs = next(iter(dataloader))  # Используем iter и next для доступа к данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843cfc43-6534-4cf7-bc21-9431d9410bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.0016, 0.0045, 0.0016,  ..., 0.0505, 0.1465, 0.1519]])] \n",
      "\n",
      "chunks_num 1 \n",
      "\n",
      "tensor([[0.0016, 0.0045, 0.0016,  ..., 0.0505, 0.1465, 0.1519]]) \n",
      "\n",
      "torch.Size([1, 32000]) \n",
      "\n",
      "---------------------------------------------- \n",
      "\n",
      "spekears num 2 \n",
      "\n",
      "firs_speaker list: [tensor([[-0.0042, -0.0083, -0.0139,  ..., -0.0009, -0.0040, -0.0038]])] \n",
      "\n",
      "chunks_nums 1 \n",
      "\n",
      "torch.Size([1, 32000]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample_mix, '\\n')\n",
    "print('chunks_num', len(sample_mix), '\\n')\n",
    "print(sample_mix[0], '\\n')\n",
    "print(sample_mix[0].shape, '\\n')\n",
    "print('----------------------------------------------', '\\n')\n",
    "print('spekears num', len(sample_refs), '\\n')\n",
    "print('firs_speaker list:', sample_refs[0], '\\n')\n",
    "print('chunks_nums', len(sample_refs[0]), '\\n')\n",
    "print(sample_refs[0][0].shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491153d-eff4-4ed1-b5bb-68035ed2f2af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Testing dataloaders LAST UPDATE 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c65159-b90f-4185-869d-8113e8da662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from utils.load_config import load_config  \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-p\", \"--hparams\", type=str, default=\"./configs/train_rnn_percent_08.yml\", help=\"hparams config file\")\n",
    "args, unknown = parser.parse_known_args()  # Игнорирует нераспознанные аргументы\n",
    "cfg = load_config(args.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a270fd5-a861-4958-aa81-92ba9990884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 3140\n",
      "Size of validation set: 641\n",
      "Elapsed time 'setup': 00:00:02.00\n"
     ]
    }
   ],
   "source": [
    "from data.DiarizationDataset import DiarizationDataset\n",
    "datamodule = DiarizationDataset(**cfg['datasets']).setup(stage = 'train')\n",
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22174481-eb62-4115-9176-6bcc8e9d4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182]])\n",
      "chunks_num 1\n",
      "tensor([0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182])\n",
      "torch.Size([32000])\n",
      "----------------------------------------------\n",
      "spekears num 2\n",
      "firs_speaker list: tensor([[ 0.0179,  0.0152,  0.0104,  ...,  0.0005, -0.0008, -0.0029]])\n",
      "chunks_nums 1\n",
      "torch.Size([32000])\n"
     ]
    }
   ],
   "source": [
    "# # Получение первого батча данных из DataLoader\n",
    "# dataloader = dataloaders['train'] \n",
    "# sample_mix, sample_refs = next(iter(dataloader))  \n",
    "# print(sample_mix)\n",
    "# print('chunks_num', len(sample_mix))\n",
    "# print(sample_mix[0])\n",
    "# print(sample_mix[0].shape)\n",
    "# print('----------------------------------------------')\n",
    "# print('spekears num', len(sample_refs))\n",
    "# print('firs_speaker list:', sample_refs[0])\n",
    "# print('chunks_nums', len(sample_refs[0]))\n",
    "# print(sample_refs[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e982a81-f8d1-4973-9b23-7b39b24e757c",
   "metadata": {},
   "source": [
    "#### Testing dataloaders LAST UPDATE. 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f08438-1181-491b-bd12-577d472318b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from utils.load_config import load_config  \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-p\", \"--hparams\", type=str, default=\"./configs/train_rnn.yml\", help=\"hparams config file\")\n",
    "args, unknown = parser.parse_known_args()  # Игнорирует нераспознанные аргументы\n",
    "cfg = load_config(args.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68d6cd7-d5a3-4ecb-8606-a9cc3746c472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 3140\n",
      "Size of validation set: 641\n",
      "Elapsed time 'setup': 00:00:02.50\n"
     ]
    }
   ],
   "source": [
    "from data.DiarizationDataset import DiarizationDataset\n",
    "\n",
    "datamodule = DiarizationDataset(**cfg['data']).setup(stage = 'train')\n",
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbfd334-a39e-476d-b91a-421e81787a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from typing import List, Tuple\n",
    "import os.path as ospth\n",
    "\n",
    "def get_file_name(file_path: str):\n",
    "    return ospth.splitext(ospth.basename(file_path))[0]\n",
    "\n",
    "def handle_df(audios: List[Tuple[int, str]]) -> dict:\n",
    "    scp_dict = dict()\n",
    "    for audio in audios:\n",
    "        common_len, l = audio\n",
    "        if len(audio) != 2:\n",
    "            raise RuntimeError(\"Format error in\")\n",
    "        if len(audio) == 2:\n",
    "            key, value = f\"{get_file_name (l)}.flac\", l\n",
    "        if key in scp_dict:\n",
    "            raise ValueError(\"Duplicated key \\'{0}\\' exists in {1}\".format(\n",
    "                l, l))\n",
    "        scp_dict[key] = {'common_len': common_len, 'name': value}\n",
    "    return scp_dict\n",
    "        \n",
    "    \n",
    "def read_wav(fname, return_rate=False):\n",
    "    '''\n",
    "         Read wavfile using Pytorch audio\n",
    "         input:\n",
    "               fname: wav file path\n",
    "               return_rate: Whether to return the sampling rate\n",
    "         output:\n",
    "                src: output tensor of size C x L \n",
    "                     L is the number of audio frames \n",
    "                     C is the number of channels. \n",
    "                sr: sample rate\n",
    "    '''\n",
    "    src, sr = torchaudio.load(fname, channels_first=True)\n",
    "    if return_rate:\n",
    "        return src.squeeze(), sr\n",
    "    else:\n",
    "        return src.squeeze()\n",
    "\n",
    "\n",
    "def write_wav(fname, src, sample_rate):\n",
    "    '''\n",
    "         Write wav file\n",
    "         input:\n",
    "               fname: wav file path\n",
    "               src: frames of audio\n",
    "               sample_rate: An integer which is the sample rate of the audio\n",
    "         output:\n",
    "               None\n",
    "    '''\n",
    "    torchaudio.save(fname, src, sample_rate)\n",
    "\n",
    "\n",
    "class CustomAudioReader(object):\n",
    "    '''\n",
    "        Class that reads Wav format files\n",
    "        Input:\n",
    "            scp_path (str): a different scp file address\n",
    "            sample_rate (int, optional): sample rate (default: 8000)\n",
    "            chunk_size (int, optional): split audio size (default: 32000(4 s))\n",
    "            least_size (int, optional): Minimum split size (default: 16000(2 s))\n",
    "        Output:\n",
    "            split audio (list)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, scp_path, sample_rate=8000, chunk_size=32000, least_size=16000):\n",
    "        super(CustomAudioReader, self).__init__()\n",
    "        self.sample_rate = sample_rate\n",
    "        self.index_dict = handle_df(scp_path)\n",
    "        self.keys = list(self.index_dict.keys())\n",
    "        # print(self.keys[0])\n",
    "        self.audio = []\n",
    "        self.chunk_size = chunk_size\n",
    "        self.least_size = least_size\n",
    "        self.split()\n",
    "\n",
    "    def split(self):\n",
    "        '''\n",
    "            split audio with chunk_size and least_size\n",
    "        '''\n",
    "        for key in self.keys:\n",
    "            common_len, name = self.index_dict[key]['common_len'], self.index_dict[key]['name']\n",
    "            utt = read_wav(name)\n",
    "            utt = utt[:common_len]\n",
    "            if utt.shape[0] < self.least_size:\n",
    "                continue\n",
    "            if utt.shape[0] > self.least_size and utt.shape[0] < self.chunk_size:\n",
    "                gap = self.chunk_size-utt.shape[0]\n",
    "                self.audio.append(F.pad(utt, (0, gap), mode='constant'))\n",
    "            if utt.shape[0] >= self.chunk_size:\n",
    "                start = 0\n",
    "                while True:\n",
    "                    if start + self.chunk_size > utt.shape[0]:\n",
    "                        break\n",
    "                    self.audio.append(utt[start:start+self.chunk_size])\n",
    "                    start += self.least_size\n",
    "\n",
    "    def get_num_after_splitting(self):\n",
    "        print(len(self.audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1eee3f8-0ee1-48eb-a9d9-de6f33e56535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class CustomDatasets(torch.utils.data.Dataset):\n",
    "    '''\n",
    "       Load audio data\n",
    "       mix_scp: file path of mix audio (type: str)\n",
    "       ref_scp: file path of ground truth audio (type: list[spk1,spk2])\n",
    "       chunk_size (int, optional): split audio size (default: 32000(4 s))\n",
    "       least_size (int, optional): Minimum split size (default: 16000(2 s))\n",
    "    '''\n",
    "\n",
    "    def __init__(self, df=None, sample_rate=16000, chunk_size=32000, least_size=16000):\n",
    "        super(torch.utils.data.Dataset, self).__init__()\n",
    "        k = len(df.iloc[0]) - 2\n",
    "        mix_scp = []\n",
    "        ref_scp = [[] for _ in range (k)]\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            common_len_idx = row['common_len_idx']\n",
    "            mix_scp.append([common_len_idx, row['mixed_audio']])\n",
    "            i = 0\n",
    "            for col in df.columns[2:]:\n",
    "                audio_value = row[col]\n",
    "                ref_scp[i].append([common_len_idx, audio_value])\n",
    "                i += 1 \n",
    "    \n",
    "        self.mix_audio = CustomAudioReader(mix_scp, sample_rate=sample_rate, chunk_size=chunk_size, least_size=least_size).audio\n",
    "        self.ref_audio = [CustomAudioReader(r, sample_rate=sample_rate, chunk_size=chunk_size, least_size=least_size).audio for r in ref_scp]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mix_audio)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.mix_audio[index], [ref[index] for ref in self.ref_audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "717663dd-4e43-4806-93fa-a7c294bd36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.measure_time import measure_time \n",
    "import torch as th\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "class TestingDiarizationDataset:\n",
    "    def __init__(self, data_root = './', train_percent = 0.75, valid_percent = 0.15, test_percent = 0.0, shuffle=False, \n",
    "                 num_workers=0, batch_size=1, pin_memory = False, sample_rate=8000, chunk_size=32000, least_size=16000, seed = 42):\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.pin_memory = pin_memory\n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self.least_size = least_size\n",
    "        self.seed = seed\n",
    "        self._set_seed(seed)\n",
    "        self.g = th.Generator()\n",
    "        self.g.manual_seed(seed)\n",
    "        full_data_df = pd.read_csv(data_root) \n",
    "        assert math.isclose(train_percent + valid_percent + test_percent, 1.0, rel_tol=1e-9), \"Sum doesnt equal to 1\" \n",
    "        train_size = int(train_percent * len(full_data_df)) \n",
    "        val_size = int(valid_percent * len(full_data_df)) \n",
    "        test_size = len(full_data_df) - train_size - val_size\n",
    "        self.train_df = full_data_df.iloc[:train_size] \n",
    "        self.val_df = full_data_df.iloc[train_size:train_size + val_size] \n",
    "        self.test_df = full_data_df.iloc[train_size + val_size:]\n",
    "         \n",
    "    @measure_time\n",
    "    def setup(self, stage = 'train'):\n",
    "        assert stage in ['train', 'eval'], \"Invalid stage\" \n",
    "        if stage == 'train': \n",
    "            self.train_dataset = CustomDatasets(self.train_df, \n",
    "                                            sample_rate = self.sample_rate,\n",
    "                                            chunk_size = self.chunk_size,\n",
    "                                            least_size = self.least_size)\n",
    "            print(f\"Size of training set: {len(self.train_dataset)}\")\n",
    "            self.val_dataset = CustomDatasets(self.val_df, \n",
    "                                        sample_rate = self.sample_rate,\n",
    "                                        chunk_size = self.chunk_size,\n",
    "                                        least_size = self.least_size)\n",
    "            print(f\"Size of validation set: {len(self.val_dataset)}\")\n",
    "        # To Do \n",
    "        # self.test_dataset\n",
    "        \n",
    "        return self # warning! \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.train_dataset,\n",
    "                                    batch_size = self.batch_size,\n",
    "                                    pin_memory = self.pin_memory,\n",
    "                                    shuffle = self.shuffle,\n",
    "                                    num_workers = self.num_workers,\n",
    "                                    worker_init_fn=self.seed_worker,\n",
    "                                    generator=self.g)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return th.utils.data.DataLoader(self.train_dataset,\n",
    "                                    batch_size = self.batch_size,\n",
    "                                    pin_memory = self.pin_memory,\n",
    "                                    shuffle = False,\n",
    "                                    num_workers = self.num_workers,\n",
    "                                    worker_init_fn=self.seed_worker,\n",
    "                                    generator=self.g)\n",
    "\n",
    "    def _set_seed(self, seed: int):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        th.manual_seed(seed)\n",
    "        th.cuda.manual_seed_all(seed)\n",
    "\n",
    "    def seed_worker(self, worker_id):\n",
    "        worker_seed = th.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "        \n",
    "    # ToDo\n",
    "    # def test_dataloader(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b33ec27-5bc7-441f-987d-6dcf7680e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 3140\n",
      "Size of validation set: 641\n",
      "Elapsed time 'setup': 00:00:02.54\n"
     ]
    }
   ],
   "source": [
    "datamodule = TestingDiarizationDataset(**cfg['data']).setup(stage = 'train')\n",
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86eab67a-d15b-410f-8119-737850f6ce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182]])\n",
      "chunks_num 1\n",
      "tensor([0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182])\n",
      "torch.Size([32000])\n",
      "----------------------------------------------\n",
      "spekears num 2\n",
      "firs_speaker list: tensor([[ 0.0179,  0.0152,  0.0104,  ...,  0.0005, -0.0008, -0.0029]])\n",
      "chunks_nums 1\n",
      "torch.Size([32000])\n"
     ]
    }
   ],
   "source": [
    "# Получение первого батча данных из DataLoader\n",
    "dataloader = dataloaders['train'] \n",
    "sample_mix, sample_refs = next(iter(dataloader))  \n",
    "print(sample_mix)\n",
    "print('chunks_num', len(sample_mix))\n",
    "print(sample_mix[0])\n",
    "print(sample_mix[0].shape)\n",
    "print('----------------------------------------------')\n",
    "print('spekears num', len(sample_refs))\n",
    "print('firs_speaker list:', sample_refs[0])\n",
    "print('chunks_nums', len(sample_refs[0]))\n",
    "print(sample_refs[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd2cea-0cee-4641-a922-94bd4a456d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182]])\n",
    "chunks_num 1\n",
    "tensor([0.0209, 0.0117, 0.0137,  ..., 0.0167, 0.0109, 0.0182])\n",
    "torch.Size([32000])\n",
    "----------------------------------------------\n",
    "spekears num 2\n",
    "firs_speaker list: tensor([[ 0.0179,  0.0152,  0.0104,  ...,  0.0005, -0.0008, -0.0029]])\n",
    "chunks_nums 1\n",
    "torch.Size([32000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2e86d-74b8-47d6-8a43-7020ac31c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of training set: 3140\n",
    "# Size of validation set: 641\n",
    "# Elapsed time 'setup': 00:00:03.57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0c6d97-73b1-415b-acdf-c64c20b4eeab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Developed | Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193324bc-b9dc-4e79-906a-79f677b42d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from losses import sdr_loss\n",
    "from torchmetrics.audio import PermutationInvariantTraining\n",
    "from torchmetrics.functional.audio import signal_distortion_ratio\n",
    "from torchmetrics.audio import SignalDistortionRatio\n",
    "\n",
    "from losses import sisnr_loss\n",
    "from torchmetrics.audio import ScaleInvariantSignalNoiseRatio\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "batch = 1\n",
    "spk = 2\n",
    "time = 3200\n",
    "sample_mix = [torch.randn(batch, time) for _ in range(spk)]\n",
    "sample_refs = [torch.randn(batch, time) for _ in range(spk)]\n",
    "\n",
    "def mix_tensors_with_similarity(tensor1, tensor2, similarity=0.05):\n",
    "    # Векторная интерполяция между tensor1 и tensor2\n",
    "    return similarity * tensor1 + (1 - similarity) * tensor2\n",
    "\n",
    "sample_mix_similar = [\n",
    "    mix_tensors_with_similarity(m, r, similarity=0.9)\n",
    "    for m, r in zip(sample_mix, sample_refs)\n",
    "]\n",
    "\n",
    "sample_mix = sample_mix_similar\n",
    "\n",
    "# Преобразуем sample_mix и sample_refs в тензоры размерности [batch, spk, time]\n",
    "sample_mix_tensor = torch.stack(sample_mix, dim=1)  # по оси 1 (spk) ожидаемый вывод: torch.Size([1, 2, 3200])\n",
    "sample_refs_tensor = torch.stack(sample_refs, dim=1)  # по оси 1 (spk)  # ожидаемый вывод: torch.Size([1, 2, 3200])\n",
    "\n",
    "pit = PermutationInvariantTraining(signal_distortion_ratio, mode=\"speaker-wise\", eval_func=\"max\")\n",
    "print('taudio:', - pit(sample_mix_tensor, sample_refs_tensor)) # Warining \"-\" minus before\n",
    "sdr = SignalDistortionRatio()\n",
    "print('another taudio:', - sdr(sample_mix_tensor, sample_refs_tensor)) # Warining \"-\" minus before\n",
    "print('my sdr:', sdr_loss(sample_mix, sample_refs), '\\n')\n",
    "\n",
    "print('my sisnr:', sisnr_loss(sample_mix, sample_refs).item())\n",
    "sisnr = ScaleInvariantSignalNoiseRatio()\n",
    "print('sisnr taudio:', - sisnr(sample_mix_tensor, sample_refs_tensor).item()) # Warining \"-\" minus before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964ef24-8aca-4b84-963d-33e355df23d0",
   "metadata": {},
   "source": [
    "Вердикт - использовать мою функцию в качестве sisnr и использовать torchaudio для sdr. \n",
    "\n",
    "Интересный факт - функция sdr ведет себя sdr(x) -> min как sisnr (x) -> min."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd01ae-9b8b-45f8-8c82-faf719452de2",
   "metadata": {},
   "source": [
    "#### Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf5e89e6-598a-4dba-93ce-1d2c8631dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from utils.load_config import load_config  \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-p\", \"--hparams\", type=str, default=\"./configs/train_rnn.yml\", help=\"hparams config file\")\n",
    "args, unknown = parser.parse_known_args()  # Игнорирует нераспознанные аргументы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614e4453-a2d5-482c-ba2b-4313e26446e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 12247\n",
      "Size of validation set: 1484\n",
      "Elapsed time 'setup': 00:00:09.94\n",
      "Trainable parametrs: 2633729\n",
      "Size of model: 10.05 MB, in float32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch.utils.tensorboard import SummaryWriter as TensorBoard\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from losses import sisnr_loss, sdr_loss\n",
    "from utils.load_config import load_config \n",
    "from utils.training import metadata_info, configure_optimizer, p_output_log\n",
    "from utils.measure_time import measure_time\n",
    "from models import Conv_TasNet, DualPath_RNN\n",
    "from data.DiarizationDataset import DiarizationDataset\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "cfg = load_config(args.hparams)\n",
    "datamodule = DiarizationDataset(**cfg['data']).setup(stage = 'train')\n",
    "dataloaders = {'train': datamodule.train_dataloader(), 'valid': datamodule.val_dataloader()}\n",
    "model = DualPath_RNN(**cfg['model'])\n",
    "metadata_info(model)\n",
    "writer = TensorBoard(f'tb_logs/{Path(args.hparams).stem}', comment = f\"{cfg['trainer']['ckpt_folder']}\")\n",
    "optimizer = configure_optimizer (cfg, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5ce649-f26c-457d-b086-5a0781fe2b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.checkpointer import Checkpointer\n",
    "from utils.training import *\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, num_epochs = 100, device='cuda', best_weights = False, checkpointing = False, \n",
    "                 checkpoint_interval = 10, model_name = '', trained_model = './', path_to_weights= './weights', \n",
    "                 ckpt_folder = '', speaker_num = 2, resume = False) -> None:\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.best_weights = best_weights\n",
    "        self.ckpointer = Checkpointer(model_name, path_to_weights, ckpt_folder, metrics = False)\n",
    "        self.checkpointing = checkpointing\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.model_name = model_name\n",
    "        os.makedirs(path_to_weights, exist_ok=True)\n",
    "        self.path_to_weights = path_to_weights\n",
    "        self.ckpt_folder = ckpt_folder\n",
    "        self.speaker_num = speaker_num\n",
    "        self.resume = resume\n",
    "        self.trained_model = trained_model\n",
    "\n",
    "    @measure_time\n",
    "    def fit(self, model, dataloaders, criterion, optimizer, writer) -> None:\n",
    "        model.to(self.device)\n",
    "        start_epoch, min_val_loss, model, optimizer = self.load_pretrained_model(model, optimizer)\n",
    "        epoch_state = EpochState(metrics = None)\n",
    "        for epoch in tqdm(range(start_epoch, self.num_epochs)):\n",
    "            for phase in ['train', 'valid']:\n",
    "                model.train() if phase == 'train' else model.eval()\n",
    "                dataloader = dataloaders[phase] \n",
    "                running_loss = 0.0\n",
    "                for inputs, labels in dataloader:\n",
    "                    inputs, labels = inputs.to(self.device), [l.to(self.device) for l in labels]\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        if phase == 'train':\n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "                epoch_loss = running_loss / len(dataloader.dataset)\n",
    "                epoch_state.update_state(epoch_loss, phase)\n",
    "                p_output_log(self.num_epochs, epoch, phase, epoch_state)\n",
    "                \n",
    "                if phase == 'valid' and self.best_weights and epoch_loss < min_val_loss:\n",
    "                    min_val_loss = epoch_loss\n",
    "                    self.ckpointer.save_best_weight(model, optimizer, epoch, epoch_state)\n",
    "            \n",
    "            torch_logger(writer, epoch, epoch_state)\n",
    "            \n",
    "            if self.checkpointing and (epoch + 1) % self.checkpoint_interval == 0:\n",
    "                self.ckpointer.save_checkpoint(model, optimizer, epoch, epoch_state)\n",
    "\n",
    "    def load_pretrained_model(self, model, optimizer):\n",
    "        if self.trained_model:\n",
    "            print(f\"Load pretrained mode: {self.trained_model}\", '\\n')\n",
    "            checkpoint = torch.load(self.trained_model, map_location=self.device, weights_only=False)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            return checkpoint['epoch'] + 1, checkpoint['val_loss'] , model, optimizer\n",
    "        else:\n",
    "            return 0, float('inf'), model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2ae70a-68fa-4c00-86b6-2d04a2def233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained mode: ./checkpoints/train_rnn/checkpoint_Dual_Path_RNN_epoch_38.pt \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74477c1af43e4544a45715b237f6db14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "TRAIN, Loss: -2.4008\n",
      "VALID, Loss: -2.2947\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 41/200\n",
      "TRAIN, Loss: -2.5803\n",
      "VALID, Loss: -2.4688\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 42/200\n",
      "TRAIN, Loss: -2.5180\n",
      "VALID, Loss: -2.2795\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 43/200\n",
      "TRAIN, Loss: -2.4638\n",
      "VALID, Loss: -2.3468\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 44/200\n",
      "TRAIN, Loss: -2.3679\n",
      "VALID, Loss: -2.4290\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 45/200\n",
      "TRAIN, Loss: -2.6124\n",
      "VALID, Loss: -2.4675\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 46/200\n",
      "TRAIN, Loss: -2.5919\n",
      "VALID, Loss: -2.3154\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 47/200\n",
      "TRAIN, Loss: -2.5945\n",
      "VALID, Loss: -2.3525\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 48/200\n",
      "TRAIN, Loss: -2.6637\n",
      "VALID, Loss: -2.5772\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 49/200\n",
      "TRAIN, Loss: -2.6366\n",
      "VALID, Loss: -2.3330\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 50/200\n",
      "TRAIN, Loss: -2.5622\n",
      "VALID, Loss: -1.9216\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 51/200\n",
      "TRAIN, Loss: -2.5347\n",
      "VALID, Loss: -2.2822\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 52/200\n",
      "TRAIN, Loss: -2.5083\n",
      "VALID, Loss: -2.3473\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 53/200\n",
      "TRAIN, Loss: -2.5410\n",
      "VALID, Loss: -2.4650\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 54/200\n",
      "TRAIN, Loss: -2.5959\n",
      "VALID, Loss: -2.5716\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 55/200\n",
      "TRAIN, Loss: -2.6884\n",
      "VALID, Loss: -2.5573\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 56/200\n",
      "TRAIN, Loss: -2.7210\n",
      "VALID, Loss: -2.6341\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 57/200\n",
      "TRAIN, Loss: -2.7234\n",
      "VALID, Loss: -2.5279\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 58/200\n",
      "TRAIN, Loss: -2.7858\n",
      "VALID, Loss: -2.6438\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 59/200\n",
      "TRAIN, Loss: -2.9084\n",
      "VALID, Loss: -2.2820\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 60/200\n",
      "TRAIN, Loss: -2.8413\n",
      "VALID, Loss: -2.5937\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 61/200\n",
      "TRAIN, Loss: -2.7052\n",
      "VALID, Loss: -2.5408\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 62/200\n",
      "TRAIN, Loss: -2.5673\n",
      "VALID, Loss: -2.3916\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 63/200\n",
      "TRAIN, Loss: -2.7080\n",
      "VALID, Loss: -2.5371\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 64/200\n",
      "TRAIN, Loss: -2.6258\n",
      "VALID, Loss: -2.3400\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 65/200\n",
      "TRAIN, Loss: -2.7073\n",
      "VALID, Loss: -2.5539\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 66/200\n",
      "TRAIN, Loss: -2.7866\n",
      "VALID, Loss: -2.6060\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 67/200\n",
      "TRAIN, Loss: -2.7699\n",
      "VALID, Loss: -2.4388\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 68/200\n",
      "TRAIN, Loss: -2.7397\n",
      "VALID, Loss: -2.7030\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 69/200\n",
      "TRAIN, Loss: -2.7983\n",
      "VALID, Loss: -2.4922\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 70/200\n",
      "TRAIN, Loss: -2.8864\n",
      "VALID, Loss: -2.6498\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 71/200\n",
      "TRAIN, Loss: -2.8990\n",
      "VALID, Loss: -2.5845\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 72/200\n",
      "TRAIN, Loss: -2.8567\n",
      "VALID, Loss: -2.5677\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 73/200\n",
      "TRAIN, Loss: -2.8924\n",
      "VALID, Loss: -2.6843\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 74/200\n",
      "TRAIN, Loss: -2.9528\n",
      "VALID, Loss: -2.6203\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 75/200\n",
      "TRAIN, Loss: -2.9743\n",
      "VALID, Loss: -2.7933\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 76/200\n",
      "TRAIN, Loss: -2.8359\n",
      "VALID, Loss: -2.6198\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 77/200\n",
      "TRAIN, Loss: -2.8703\n",
      "VALID, Loss: -2.7223\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 78/200\n",
      "TRAIN, Loss: -2.8726\n",
      "VALID, Loss: -2.1306\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 79/200\n",
      "TRAIN, Loss: -2.9039\n",
      "VALID, Loss: -2.5910\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 80/200\n",
      "TRAIN, Loss: -2.8790\n",
      "VALID, Loss: -2.3030\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 81/200\n",
      "TRAIN, Loss: -2.8828\n",
      "VALID, Loss: -2.6391\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 82/200\n",
      "TRAIN, Loss: -2.9484\n",
      "VALID, Loss: -2.5590\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 83/200\n",
      "TRAIN, Loss: -3.0024\n",
      "VALID, Loss: -2.6986\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 84/200\n",
      "TRAIN, Loss: -2.7941\n",
      "VALID, Loss: -2.3283\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 85/200\n",
      "TRAIN, Loss: -2.8126\n",
      "VALID, Loss: -2.7055\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 86/200\n",
      "TRAIN, Loss: -2.9332\n",
      "VALID, Loss: -2.6285\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 87/200\n",
      "TRAIN, Loss: -2.9564\n",
      "VALID, Loss: -2.6007\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 88/200\n",
      "TRAIN, Loss: -3.0089\n",
      "VALID, Loss: -2.7856\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 89/200\n",
      "TRAIN, Loss: -3.0395\n",
      "VALID, Loss: -2.7487\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 90/200\n",
      "TRAIN, Loss: -3.0023\n",
      "VALID, Loss: -2.6296\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 91/200\n",
      "TRAIN, Loss: -3.1401\n",
      "VALID, Loss: -2.6870\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 92/200\n",
      "TRAIN, Loss: -3.0788\n",
      "VALID, Loss: -2.6866\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 93/200\n",
      "TRAIN, Loss: -3.0692\n",
      "VALID, Loss: -2.4984\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 94/200\n",
      "TRAIN, Loss: -2.9572\n",
      "VALID, Loss: -2.5987\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 95/200\n",
      "TRAIN, Loss: -2.9873\n",
      "VALID, Loss: -2.7808\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 96/200\n",
      "TRAIN, Loss: -2.9510\n",
      "VALID, Loss: -2.7343\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 97/200\n",
      "TRAIN, Loss: -3.0681\n",
      "VALID, Loss: -2.7402\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 98/200\n",
      "TRAIN, Loss: -3.0223\n",
      "VALID, Loss: -2.8000\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 99/200\n",
      "TRAIN, Loss: -3.0731\n",
      "VALID, Loss: -2.8490\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 100/200\n",
      "TRAIN, Loss: -3.1412\n",
      "VALID, Loss: -2.5912\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 101/200\n",
      "TRAIN, Loss: -3.0763\n",
      "VALID, Loss: -2.8057\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 102/200\n",
      "TRAIN, Loss: -3.0994\n",
      "VALID, Loss: -2.7180\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 103/200\n",
      "TRAIN, Loss: -3.2409\n",
      "VALID, Loss: -2.8788\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 104/200\n",
      "TRAIN, Loss: -3.0887\n",
      "VALID, Loss: -2.8059\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 105/200\n",
      "TRAIN, Loss: -3.1994\n",
      "VALID, Loss: -2.7007\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 106/200\n",
      "TRAIN, Loss: -3.0799\n",
      "VALID, Loss: -2.7600\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 107/200\n",
      "TRAIN, Loss: -3.2579\n",
      "VALID, Loss: -2.7688\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 108/200\n",
      "TRAIN, Loss: -3.1838\n",
      "VALID, Loss: -2.4712\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 109/200\n",
      "TRAIN, Loss: -3.0280\n",
      "VALID, Loss: -2.7465\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 110/200\n",
      "TRAIN, Loss: -3.1277\n",
      "VALID, Loss: -2.6555\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 111/200\n",
      "TRAIN, Loss: -3.2738\n",
      "VALID, Loss: -2.8946\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 112/200\n",
      "TRAIN, Loss: -3.2792\n",
      "VALID, Loss: -2.8394\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 113/200\n",
      "TRAIN, Loss: -3.2352\n",
      "VALID, Loss: -2.7588\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 114/200\n",
      "TRAIN, Loss: -3.2493\n",
      "VALID, Loss: -2.8235\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 115/200\n",
      "TRAIN, Loss: -3.2772\n",
      "VALID, Loss: -2.6794\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 116/200\n",
      "TRAIN, Loss: -3.2258\n",
      "VALID, Loss: -2.6952\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 117/200\n",
      "TRAIN, Loss: -3.1605\n",
      "VALID, Loss: -2.7703\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 118/200\n",
      "TRAIN, Loss: -3.2453\n",
      "VALID, Loss: -2.7517\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 119/200\n",
      "TRAIN, Loss: -3.3598\n",
      "VALID, Loss: -2.8700\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 120/200\n",
      "TRAIN, Loss: -3.4267\n",
      "VALID, Loss: -2.7962\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 121/200\n",
      "TRAIN, Loss: -3.3744\n",
      "VALID, Loss: -2.8903\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 122/200\n",
      "TRAIN, Loss: -3.3132\n",
      "VALID, Loss: -2.5200\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 123/200\n",
      "TRAIN, Loss: -3.3767\n",
      "VALID, Loss: -2.9812\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 124/200\n",
      "TRAIN, Loss: -3.3754\n",
      "VALID, Loss: -2.8346\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 125/200\n",
      "TRAIN, Loss: -3.4571\n",
      "VALID, Loss: -2.8413\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 126/200\n",
      "TRAIN, Loss: -3.3817\n",
      "VALID, Loss: -2.8782\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 127/200\n",
      "TRAIN, Loss: -3.4272\n",
      "VALID, Loss: -2.7225\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 128/200\n",
      "TRAIN, Loss: -3.4321\n",
      "VALID, Loss: -2.9409\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 129/200\n",
      "TRAIN, Loss: -3.5164\n",
      "VALID, Loss: -2.9270\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 130/200\n",
      "TRAIN, Loss: -3.5124\n",
      "VALID, Loss: -2.9084\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 131/200\n",
      "TRAIN, Loss: -3.4649\n",
      "VALID, Loss: -2.9757\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 132/200\n",
      "TRAIN, Loss: -3.5057\n",
      "VALID, Loss: -2.8753\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 133/200\n",
      "TRAIN, Loss: -3.6223\n",
      "VALID, Loss: -3.1076\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 134/200\n",
      "TRAIN, Loss: -3.5947\n",
      "VALID, Loss: -3.0054\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 135/200\n",
      "TRAIN, Loss: -3.5906\n",
      "VALID, Loss: -3.0350\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 136/200\n",
      "TRAIN, Loss: -3.5977\n",
      "VALID, Loss: -2.9212\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 137/200\n",
      "TRAIN, Loss: -3.5976\n",
      "VALID, Loss: -3.0725\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 138/200\n",
      "TRAIN, Loss: -3.6546\n",
      "VALID, Loss: -2.9627\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 139/200\n",
      "TRAIN, Loss: -3.5949\n",
      "VALID, Loss: -2.6900\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 140/200\n",
      "TRAIN, Loss: -3.5423\n",
      "VALID, Loss: -2.9485\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 141/200\n",
      "TRAIN, Loss: -3.3502\n",
      "VALID, Loss: -2.9022\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 142/200\n",
      "TRAIN, Loss: -3.3227\n",
      "VALID, Loss: -2.8606\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 143/200\n",
      "TRAIN, Loss: -3.4888\n",
      "VALID, Loss: -2.6157\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 144/200\n",
      "TRAIN, Loss: -3.4573\n",
      "VALID, Loss: -2.7791\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 145/200\n",
      "TRAIN, Loss: -3.5383\n",
      "VALID, Loss: -2.9148\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 146/200\n",
      "TRAIN, Loss: -3.5804\n",
      "VALID, Loss: -3.0148\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 147/200\n",
      "TRAIN, Loss: -3.5869\n",
      "VALID, Loss: -2.9554\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 148/200\n",
      "TRAIN, Loss: -3.5931\n",
      "VALID, Loss: -2.9800\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 149/200\n",
      "TRAIN, Loss: -3.5858\n",
      "VALID, Loss: -3.0046\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 150/200\n",
      "TRAIN, Loss: -3.6150\n",
      "VALID, Loss: -3.0586\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 151/200\n",
      "TRAIN, Loss: -3.7006\n",
      "VALID, Loss: -3.0902\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 152/200\n",
      "TRAIN, Loss: -3.6564\n",
      "VALID, Loss: -2.9905\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 153/200\n",
      "TRAIN, Loss: -3.6592\n",
      "VALID, Loss: -3.0773\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 154/200\n",
      "TRAIN, Loss: -3.6875\n",
      "VALID, Loss: -2.7888\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 155/200\n",
      "TRAIN, Loss: -3.6844\n",
      "VALID, Loss: -3.0986\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 156/200\n",
      "TRAIN, Loss: -3.7179\n",
      "VALID, Loss: -2.9974\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 157/200\n",
      "TRAIN, Loss: -3.6930\n",
      "VALID, Loss: -2.9983\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 158/200\n",
      "TRAIN, Loss: -3.6317\n",
      "VALID, Loss: -2.9947\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 159/200\n",
      "TRAIN, Loss: -3.5357\n",
      "VALID, Loss: -2.7213\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 160/200\n",
      "TRAIN, Loss: -3.6227\n",
      "VALID, Loss: -2.8707\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 161/200\n",
      "TRAIN, Loss: -3.7038\n",
      "VALID, Loss: -3.0109\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 162/200\n",
      "TRAIN, Loss: -3.6927\n",
      "VALID, Loss: -3.0368\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 163/200\n",
      "TRAIN, Loss: -3.6800\n",
      "VALID, Loss: -2.8741\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 164/200\n",
      "TRAIN, Loss: -3.6952\n",
      "VALID, Loss: -2.9893\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 165/200\n",
      "TRAIN, Loss: -3.7579\n",
      "VALID, Loss: -3.0473\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 166/200\n",
      "TRAIN, Loss: -3.6732\n",
      "VALID, Loss: -3.0400\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 167/200\n",
      "TRAIN, Loss: -3.7553\n",
      "VALID, Loss: -3.0574\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 168/200\n",
      "TRAIN, Loss: -3.7717\n",
      "VALID, Loss: -3.0640\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 169/200\n",
      "TRAIN, Loss: -3.7013\n",
      "VALID, Loss: -3.1209\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 170/200\n",
      "TRAIN, Loss: -3.7612\n",
      "VALID, Loss: -3.0634\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 171/200\n",
      "TRAIN, Loss: -3.6870\n",
      "VALID, Loss: -3.0295\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 172/200\n",
      "TRAIN, Loss: -3.8287\n",
      "VALID, Loss: -2.9071\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 173/200\n",
      "TRAIN, Loss: -3.6804\n",
      "VALID, Loss: -3.0058\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 174/200\n",
      "TRAIN, Loss: -3.8361\n",
      "VALID, Loss: -3.0208\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 175/200\n",
      "TRAIN, Loss: -3.8357\n",
      "VALID, Loss: -3.1363\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 176/200\n",
      "TRAIN, Loss: -3.8846\n",
      "VALID, Loss: -3.1298\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 177/200\n",
      "TRAIN, Loss: -3.8427\n",
      "VALID, Loss: -3.0065\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 178/200\n",
      "TRAIN, Loss: -3.5238\n",
      "VALID, Loss: -2.9313\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 179/200\n",
      "TRAIN, Loss: -3.7421\n",
      "VALID, Loss: -3.0867\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 180/200\n",
      "TRAIN, Loss: -3.8540\n",
      "VALID, Loss: -3.1895\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 181/200\n",
      "TRAIN, Loss: -3.9502\n",
      "VALID, Loss: -3.1068\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 182/200\n",
      "TRAIN, Loss: -3.7038\n",
      "VALID, Loss: -3.0082\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 183/200\n",
      "TRAIN, Loss: -3.7370\n",
      "VALID, Loss: -2.8831\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 184/200\n",
      "TRAIN, Loss: -3.7649\n",
      "VALID, Loss: -2.9348\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 185/200\n",
      "TRAIN, Loss: -3.8361\n",
      "VALID, Loss: -2.9818\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 186/200\n",
      "TRAIN, Loss: -3.7075\n",
      "VALID, Loss: -3.0829\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 187/200\n",
      "TRAIN, Loss: -3.8856\n",
      "VALID, Loss: -3.1038\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 188/200\n",
      "TRAIN, Loss: -3.6928\n",
      "VALID, Loss: -2.9497\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 189/200\n",
      "TRAIN, Loss: -3.9587\n",
      "VALID, Loss: -3.0671\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 190/200\n",
      "TRAIN, Loss: -3.7973\n",
      "VALID, Loss: -2.9874\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 191/200\n",
      "TRAIN, Loss: -3.9760\n",
      "VALID, Loss: -2.9805\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 192/200\n",
      "TRAIN, Loss: -3.9485\n",
      "VALID, Loss: -2.9787\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 193/200\n",
      "TRAIN, Loss: -3.8546\n",
      "VALID, Loss: -2.9925\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 194/200\n",
      "TRAIN, Loss: -3.9285\n",
      "VALID, Loss: -3.1272\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 195/200\n",
      "TRAIN, Loss: -4.0370\n",
      "VALID, Loss: -3.1175\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 196/200\n",
      "TRAIN, Loss: -3.9529\n",
      "VALID, Loss: -3.1186\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 197/200\n",
      "TRAIN, Loss: -4.0235\n",
      "VALID, Loss: -2.6843\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 198/200\n",
      "TRAIN, Loss: -4.0225\n",
      "VALID, Loss: -3.0730\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 199/200\n",
      "TRAIN, Loss: -4.0234\n",
      "VALID, Loss: -3.1722\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Epoch 200/200\n",
      "TRAIN, Loss: -4.0699\n",
      "VALID, Loss: -3.1555\n",
      "------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Elapsed time 'fit': 59:48:12.00\n"
     ]
    }
   ],
   "source": [
    "Trainer(**cfg['trainer']).fit(model, \n",
    "                              dataloaders, \n",
    "                              sisnr_loss, \n",
    "                              optimizer, \n",
    "                              writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0192f-2691-4e79-8aed-bac42cbb4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
